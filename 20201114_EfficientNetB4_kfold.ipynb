{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XDnap1jLv8so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as pth\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffY3gSLAvvSs"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = 'ResNet50V2-kfold'\n",
    "my_model_base = keras.applications.resnet_v2\n",
    "my_model = my_model_base.ResNet50V2\n",
    "\n",
    "config = {\n",
    "    'is_zscore':True,\n",
    "    \n",
    "    # 'input_shape': (540, 960, 3),\n",
    "    'aug': {\n",
    "        'resize': (270, 480),\n",
    "        #'resize': (297, 528),\n",
    "    },\n",
    "    # 'input_shape': (224, 360, 3),\n",
    "    #'input_shape': (270, 480, 3),\n",
    "    'input_shape': (270, 480, 3),\n",
    "\n",
    "    'output_activation': 'softmax',\n",
    "    'num_class': 1049,\n",
    "    'output_size': 1049,\n",
    "    \n",
    "    'conv':{\n",
    "        'conv_num': (0,), # (3,5,3),\n",
    "        'base_channel': 0, # 4,\n",
    "        'kernel_size': 0, # 3,\n",
    "        'padding':'same',\n",
    "        'stride':'X'\n",
    "    },\n",
    "    'pool':{\n",
    "        'type':'X',\n",
    "        'size':'X',\n",
    "        'stride':'X',\n",
    "        'padding':'same'\n",
    "    },\n",
    "    'fc':{\n",
    "        'fc_num': 0,\n",
    "     },\n",
    "    \n",
    "    'activation':'relu',\n",
    "    \n",
    "    'between_type': 'avg',\n",
    "    \n",
    "    'is_batchnorm': True,\n",
    "    'is_dropout': False,\n",
    "    'dropout_rate': 0.5,\n",
    "    \n",
    "    'batch_size': 80,\n",
    "    'buffer_size': 256,\n",
    "    'loss': 'CategoricalCrossentropy',\n",
    "    \n",
    "    #'num_epoch': 10000,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    'random_state': 7777\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "abOw4s0jv6JI"
   },
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'landmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['landmark_id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def resize_and_crop_func(image, label):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    #result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # crop revived.\n",
    "    return result_image, label\n",
    "\n",
    "def image_aug_func(image, label):\n",
    "    pass\n",
    "    return image, label\n",
    "\n",
    "def post_process_func(image, label):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    onehot_label = tf.one_hot(label, depth=config['num_class'])\n",
    "    return result_image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j1UN3LYJzFgd"
   },
   "outputs": [],
   "source": [
    "data_base_path = pth.join('data', 'public') \n",
    "os.makedirs(data_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ks1l_51cNzLP"
   },
   "outputs": [],
   "source": [
    "category_csv_name = 'category.csv'\n",
    "category_json_name = 'category.json'\n",
    "submission_csv_name = 'sample_submisstion.csv'\n",
    "train_csv_name = 'train.csv'\n",
    "\n",
    "# train_zip_name = 'train.zip'\n",
    "train_tfrecord_name = 'all_train.tfrecords'\n",
    "train_tfrecord_path = pth.join(data_base_path, train_tfrecord_name)\n",
    "val_tfrecord_name = 'all_val.tfrecords'\n",
    "val_tfrecord_path = pth.join(data_base_path, val_tfrecord_name)\n",
    "# test_zip_name = 'test.zip'\n",
    "test_tfrecord_name = 'test.tfrecords'\n",
    "test_tfrecord_path = pth.join(data_base_path, test_tfrecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MaBBHyX0dMig"
   },
   "outputs": [],
   "source": [
    "train_csv_path = pth.join(data_base_path, train_csv_name)\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_dict = {k:v for k, v in train_df.values}\n",
    "\n",
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "# submission_df.head()\n",
    "\n",
    "category_csv_path = pth.join(data_base_path, category_csv_name)\n",
    "category_df = pd.read_csv(category_csv_path)\n",
    "category_dict = {k:v for k, v in category_df.values}\n",
    "# category_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdng6pk8k0fH"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q9-4T5OMcy1R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, GroupKFold, RepeatedStratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as pth\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import datetime\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv3D, AveragePooling3D, MaxPooling3D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool3D, GlobalAvgPool3D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAaKPD3cnKB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WrRPrv1aoOEA"
   },
   "outputs": [],
   "source": [
    "def build_cnn(config):\n",
    "    input_layer = Input(shape=config['input_shape'], name='input_layer')\n",
    "    pret_model = my_model(\n",
    "        input_tensor=input_layer, include_top=False, weights='imagenet', \n",
    "        input_shape=config['input_shape'], pooling=config['between_type'], \n",
    "        classes=config['output_size']\n",
    "    )\n",
    "\n",
    "    pret_model.trainable = False\n",
    "    \n",
    "    x = pret_model.output\n",
    "    \n",
    "    if config['between_type'] == None:\n",
    "        x = Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "    if config['is_dropout']:\n",
    "        x = Dropout(config['dropout_rate'], name='output_dropout')(x)    \n",
    "            \n",
    "    x = Dense(config['output_size'], activation=config['output_activation'], \n",
    "          name='output_fc')(x)\n",
    "#     x = Activation(activation=config['output_activation'], name='output_activation')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x, name='{}'.format(BASE_MODEL_NAME))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d5mZ06q3qAmN",
    "outputId": "edc1edc4-147a-43c3-e8c4-0ae69fa5e59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50V2-kfold\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_layer (InputLayer)                         [(None, 270, 480, 3)]            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)                        (None, 276, 486, 3)              0                 input_layer[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)                              (None, 135, 240, 64)             9472              conv1_pad[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)                        (None, 137, 242, 64)             0                 conv1_conv[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)                        (None, 68, 120, 64)              0                 pool1_pad[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNormalization)      (None, 68, 120, 64)              256               pool1_pool[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activation)            (None, 68, 120, 64)              0                 conv2_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)                     (None, 68, 120, 64)              4096              conv2_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)                     (None, 68, 120, 64)              36864             conv2_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)                           (None, 68, 120, 256)             0                 conv2_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv2_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNormalization)      (None, 68, 120, 256)             1024              conv2_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activation)            (None, 68, 120, 256)             0                 conv2_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)                     (None, 68, 120, 64)              16384             conv2_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)                     (None, 68, 120, 64)              36864             conv2_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)                           (None, 68, 120, 256)             0                 conv2_block1_out[0][0]                            \n",
      "                                                                                                    conv2_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNormalization)      (None, 68, 120, 256)             1024              conv2_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activation)            (None, 68, 120, 256)             0                 conv2_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)                     (None, 68, 120, 64)              16384             conv2_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)                     (None, 34, 60, 64)               36864             conv2_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormalization)           (None, 34, 60, 64)               256               conv2_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation)                 (None, 34, 60, 64)               0                 conv2_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)                     (None, 34, 60, 256)              0                 conv2_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)                     (None, 34, 60, 256)              16640             conv2_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)                           (None, 34, 60, 256)              0                 max_pooling2d[0][0]                               \n",
      "                                                                                                    conv2_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNormalization)      (None, 34, 60, 256)              1024              conv2_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activation)            (None, 34, 60, 256)              0                 conv3_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)                     (None, 34, 60, 128)              32768             conv3_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)                     (None, 34, 60, 512)              131584            conv3_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)                           (None, 34, 60, 512)              0                 conv3_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv3_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)                           (None, 34, 60, 512)              0                 conv3_block1_out[0][0]                            \n",
      "                                                                                                    conv3_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)                           (None, 34, 60, 512)              0                 conv3_block2_out[0][0]                            \n",
      "                                                                                                    conv3_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block4_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block4_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block4_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block4_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block4_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)                     (None, 17, 30, 128)              147456            conv3_block4_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormalization)           (None, 17, 30, 128)              512               conv3_block4_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation)                 (None, 17, 30, 128)              0                 conv3_block4_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)                   (None, 17, 30, 512)              0                 conv3_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)                     (None, 17, 30, 512)              66048             conv3_block4_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)                           (None, 17, 30, 512)              0                 max_pooling2d_1[0][0]                             \n",
      "                                                                                                    conv3_block4_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNormalization)      (None, 17, 30, 512)              2048              conv3_block4_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activation)            (None, 17, 30, 512)              0                 conv4_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)                     (None, 17, 30, 256)              131072            conv4_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)                     (None, 17, 30, 1024)             525312            conv4_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv4_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block1_out[0][0]                            \n",
      "                                                                                                    conv4_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block2_out[0][0]                            \n",
      "                                                                                                    conv4_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block4_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block4_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block4_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block4_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block4_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block4_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block4_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block4_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block4_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block3_out[0][0]                            \n",
      "                                                                                                    conv4_block4_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block4_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block5_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block5_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block5_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block5_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block5_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block5_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block5_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block5_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block5_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block4_out[0][0]                            \n",
      "                                                                                                    conv4_block5_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block5_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block6_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block6_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block6_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block6_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block6_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)                     (None, 9, 15, 256)               589824            conv4_block6_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormalization)           (None, 9, 15, 256)               1024              conv4_block6_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation)                 (None, 9, 15, 256)               0                 conv4_block6_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)                   (None, 9, 15, 1024)              0                 conv4_block5_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)                     (None, 9, 15, 1024)              263168            conv4_block6_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)                           (None, 9, 15, 1024)              0                 max_pooling2d_2[0][0]                             \n",
      "                                                                                                    conv4_block6_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNormalization)      (None, 9, 15, 1024)              4096              conv4_block6_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activation)            (None, 9, 15, 1024)              0                 conv5_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)                     (None, 9, 15, 512)               524288            conv5_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)                     (None, 9, 15, 2048)              2099200           conv5_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv5_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNormalization)      (None, 9, 15, 2048)              8192              conv5_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activation)            (None, 9, 15, 2048)              0                 conv5_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)                     (None, 9, 15, 512)               1048576           conv5_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block1_out[0][0]                            \n",
      "                                                                                                    conv5_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNormalization)      (None, 9, 15, 2048)              8192              conv5_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activation)            (None, 9, 15, 2048)              0                 conv5_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)                     (None, 9, 15, 512)               1048576           conv5_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block2_out[0][0]                            \n",
      "                                                                                                    conv5_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)                     (None, 9, 15, 2048)              8192              conv5_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "post_relu (Activation)                           (None, 9, 15, 2048)              0                 post_bn[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D)                (None, 2048)                     0                 post_relu[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "output_fc (Dense)                                (None, 1049)                     2149401           avg_pool[0][0]                                    \n",
      "======================================================================================================================================================\n",
      "Total params: 25,714,201\n",
      "Trainable params: 2,149,401\n",
      "Non-trainable params: 23,564,800\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(config)\n",
    "model.summary(line_length=150)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCsZqqHyqAds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YzKzI0vXsrJp"
   },
   "outputs": [],
   "source": [
    "model_base_path = data_base_path\n",
    "model_checkpoint_path = pth.join(model_base_path, 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "FILENAMES = tf.io.gfile.glob(pth.join(data_base_path, 'train_tfrec', '*'))\n",
    "TEST_FILENAMES = tf.io.gfile.glob(pth.join(data_base_path, 'test_tfrec', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training tfrecords \n",
    "def read_tr_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"landmark_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     target = tf.cast(example['landmark_id'], tf.int64)\n",
    "#     return image, target\n",
    "\n",
    "# validation tfrecords \n",
    "def read_val_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"landmark_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     target = tf.cast(example['landmark_id'], tf.int64)\n",
    "#     return image, target\n",
    "\n",
    "# test tfrecords \n",
    "def read_test_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     id = example['id']\n",
    "#     return image, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(filenames, ordered = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_tr_tfrecord, num_parallel_calls = AUTO)\n",
    "\n",
    "    #dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # dataset = dataset.cache()\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(config['buffer_size'])\n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset(filenames, ordered = True, prediction = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_val_tfrecord, num_parallel_calls = AUTO)\n",
    "    \n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if prediction:\n",
    "        dataset = dataset.batch(config['batch_size'] * 4)  # why 4 times?\n",
    "    else:\n",
    "        dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_just_image(image, id):\n",
    "    return image\n",
    "def test_just_id(image, id):\n",
    "    return id\n",
    "\n",
    "def get_test_dataset(filenames, ordered=True, prediction=False, name=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_test_tfrecord, num_parallel_calls = AUTO)\n",
    "    \n",
    "    #dataset = load_dataset(filenames, tr='test', ordered = ordered)\n",
    "    if name:\n",
    "        dataset = dataset.map(test_just_id, num_parallel_calls = AUTO)\n",
    "    else:\n",
    "        dataset = dataset.map(test_just_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\n",
    "SEED = 42\n",
    "\n",
    "# NUMBER OF FOLDS. USE 3, 5, OR 15 \n",
    "FOLDS = 5\n",
    "\n",
    "#BATCH_SIZES = [32]*FOLDS\n",
    "EPOCHS = [8]*FOLDS\n",
    "\n",
    "PRE_TRAIN_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 0.000001*10*0.5\n",
    "    lr_max     = 0.0000005 * config['batch_size'] * 10*0.5\n",
    "    lr_min     = 0.000001 * 10*0.5\n",
    "    #lr_ramp_ep = 3 #### TODO: NEED TO BE CONSIDERED WISELY.  # 5\n",
    "    lr_ramp_ep = 3 #### (small lr) going up -> ramp (large max lr) -> going down (small lr)\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "     \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max    \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "        print('lr=',lr)\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BASE_MODEL_NAME\n",
    "\n",
    "base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "#base += '_input_{}'.format(config['input_shape'][0])\n",
    "base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "base += '_act_{}'.format(config['activation'])\n",
    "base += '_pool_{}'.format(config['pool']['type'])\n",
    "base += '_betw_{}'.format(config['between_type'])\n",
    "base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "base += '_zscore_{}'.format(config['is_zscore'])\n",
    "base += '_batch_{}'.format(config['batch_size'])\n",
    "if config['is_dropout']:\n",
    "    base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "if config['is_batchnorm']:\n",
    "    base += '_BN'+'_O'\n",
    "else:\n",
    "    base += '_BN'+'_X'\n",
    "\n",
    "model_name = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ta_kqsLstQcV",
    "outputId": "760909ad-2f6c-444c-aa85-43ab5e364c6b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### FOLD 2\n",
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "#########################\n",
      "FILENAMES= 88102\n",
      "TRAINING_FILENAMES= 70481\n",
      "VALIDATION_FILENAMES= 17621\n",
      "STEPS_PER_EPOCH= 882.0\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "lr= 4.9999999999999996e-06\n",
      "Epoch 1/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0527 - acc: 0.9882 - precision: 0.9949 - recall: 0.9849 - auc: 0.9988\n",
      "Epoch 00001: val_loss improved from inf to 0.00121, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000001-0.001208-0.052671.hdf5\n",
      "882/882 [==============================] - 663s 751ms/step - loss: 0.0527 - acc: 0.9882 - precision: 0.9949 - recall: 0.9849 - auc: 0.9988 - val_loss: 0.0012 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "lr= 7e-05\n",
      "Epoch 2/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.9915 - precision: 0.9969 - recall: 0.9870 - auc: 0.9995\n",
      "Epoch 00002: val_loss did not improve from 0.00121\n",
      "882/882 [==============================] - 663s 752ms/step - loss: 0.0424 - acc: 0.9915 - precision: 0.9969 - recall: 0.9870 - auc: 0.9995 - val_loss: 0.0069 - val_acc: 0.9998 - val_precision: 0.9999 - val_recall: 0.9997 - val_auc: 1.0000\n",
      "lr= 0.00013499999999999997\n",
      "Epoch 3/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00003: val_loss did not improve from 0.00121\n",
      "882/882 [==============================] - 663s 752ms/step - loss: 0.0044 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9998 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000\n",
      "lr= 0.00019999999999999998\n",
      "Epoch 4/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 9.0052e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00004: val_loss did not improve from 0.00121\n",
      "882/882 [==============================] - 664s 753ms/step - loss: 9.0052e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9999 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000\n",
      "lr= 0.000161\n",
      "Epoch 5/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 3.9648e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00005: val_loss improved from 0.00121 to 0.00092, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000005-0.000918-0.000396.hdf5\n",
      "882/882 [==============================] - 665s 754ms/step - loss: 3.9648e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1765e-04 - val_acc: 0.9999 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000\n",
      "lr= 0.0001298\n",
      "Epoch 6/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 2.4303e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00006: val_loss improved from 0.00092 to 0.00084, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000006-0.000843-0.000243.hdf5\n",
      "882/882 [==============================] - 663s 752ms/step - loss: 2.4303e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4327e-04 - val_acc: 0.9999 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000\n",
      "lr= 0.00010484\n",
      "Epoch 7/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0303 - acc: 0.9942 - precision: 0.9969 - recall: 0.9898 - auc: 0.9999\n",
      "Epoch 00007: val_loss did not improve from 0.00084\n",
      "882/882 [==============================] - 664s 753ms/step - loss: 0.0303 - acc: 0.9942 - precision: 0.9969 - recall: 0.9898 - auc: 0.9999 - val_loss: 0.0449 - val_acc: 0.9886 - val_precision: 0.9936 - val_recall: 0.9833 - val_auc: 0.9999\n",
      "lr= 8.4872e-05\n",
      "Epoch 8/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9988 - precision: 0.9993 - recall: 0.9980 - auc: 1.0000\n",
      "Epoch 00008: val_loss did not improve from 0.00084\n",
      "882/882 [==============================] - 664s 753ms/step - loss: 0.0088 - acc: 0.9988 - precision: 0.9993 - recall: 0.9980 - auc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9948 - val_precision: 0.9973 - val_recall: 0.9925 - val_auc: 1.0000\n",
      "#########################\n",
      "#### FOLD 3\n",
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "#########################\n",
      "FILENAMES= 88102\n",
      "TRAINING_FILENAMES= 70482\n",
      "VALIDATION_FILENAMES= 17620\n",
      "STEPS_PER_EPOCH= 882.0\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "lr= 4.9999999999999996e-06\n",
      "Epoch 1/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 4.8497e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00001: val_loss improved from inf to 0.00011, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000001-0.000110-0.000485.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 4.8497e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1034e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "lr= 7e-05\n",
      "Epoch 2/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9985 - precision: 0.9991 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 00002: val_loss did not improve from 0.00011\n",
      "882/882 [==============================] - 665s 754ms/step - loss: 0.0107 - acc: 0.9985 - precision: 0.9991 - recall: 0.9977 - auc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9994 - val_precision: 0.9995 - val_recall: 0.9992 - val_auc: 1.0000\n",
      "lr= 0.00013499999999999997\n",
      "Epoch 3/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0268 - acc: 0.9950 - precision: 0.9970 - recall: 0.9917 - auc: 0.9999\n",
      "Epoch 00003: val_loss did not improve from 0.00011\n",
      "882/882 [==============================] - 665s 754ms/step - loss: 0.0268 - acc: 0.9950 - precision: 0.9970 - recall: 0.9917 - auc: 0.9999 - val_loss: 0.0389 - val_acc: 0.9916 - val_precision: 0.9957 - val_recall: 0.9865 - val_auc: 0.9998\n",
      "lr= 0.00019999999999999998\n",
      "Epoch 4/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9964 - precision: 0.9977 - recall: 0.9943 - auc: 0.9999\n",
      "Epoch 00004: val_loss did not improve from 0.00011\n",
      "882/882 [==============================] - 664s 753ms/step - loss: 0.0204 - acc: 0.9964 - precision: 0.9977 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0482 - val_acc: 0.9872 - val_precision: 0.9918 - val_recall: 0.9838 - val_auc: 0.9995\n",
      "lr= 0.000161\n",
      "Epoch 5/8\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9995 - precision: 0.9996 - recall: 0.9994 - auc: 1.0000\n",
      "Epoch 00005: val_loss did not improve from 0.00011\n",
      "882/882 [==============================] - 665s 754ms/step - loss: 0.0037 - acc: 0.9995 - precision: 0.9996 - recall: 0.9994 - auc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9904 - val_precision: 0.9943 - val_recall: 0.9876 - val_auc: 0.9997\n",
      "lr= 0.0001298\n",
      "Epoch 6/8\n",
      "211/882 [======>.......................] - ETA: 7:00 - loss: 7.4071e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "FILENAMES = np.array(FILENAMES)\n",
    "\n",
    "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [] \n",
    "#preds = np.zeros((count_data_items(files_test),1))\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True,random_state=SEED)\n",
    "for fold, (tr_index, val_index) in enumerate(skf.split(FILENAMES)):\n",
    "\n",
    "#     if fold == 0:\n",
    "#         continue\n",
    "\n",
    "    print('#'*25); print('#### FOLD',fold+1)\n",
    "    #gc.collect()\n",
    "    \n",
    "    #print('################', 'lr=', LEARNING_RATE)\n",
    "    print(model_name)\n",
    "\n",
    "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
    "    #NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "  \n",
    "    np.random.shuffle(TRAINING_FILENAMES); print('#'*25)\n",
    "    #seed_everything(SEED)\n",
    "    \n",
    "    train_dataset = get_training_dataset(TRAINING_FILENAMES,ordered = False)\n",
    "    val_dataset = get_validation_dataset(VALIDATION_FILENAMES,ordered = True, prediction = False)\n",
    "    \n",
    "    print('FILENAMES=', len(FILENAMES))\n",
    "    print('TRAINING_FILENAMES=', len(TRAINING_FILENAMES))\n",
    "    print('VALIDATION_FILENAMES=', len(VALIDATION_FILENAMES))\n",
    "    STEPS_PER_EPOCH = np.ceil(len(TRAINING_FILENAMES)/config['batch_size'])\n",
    "    print('STEPS_PER_EPOCH=', STEPS_PER_EPOCH)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "#     model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "#                   metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    if pth.isdir(model_path) and len([_ for _ in os.listdir(model_path) if _.endswith('hdf5')]) >= 1:\n",
    "        for layer in model.layers[:166]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[166:]:\n",
    "            layer.trainable = True\n",
    "            \n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "        model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "        initial_epoch = int(model_chk_name.split('-')[0])\n",
    "        model.load_weights(pth.join(model_path, model_chk_name))\n",
    "    else:\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                     metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        \n",
    "        model.fit(\n",
    "            x=train_dataset, epochs=PRE_TRAIN_EPOCH, # train only top layers for just a few epochs.\n",
    "            validation_data=val_dataset, shuffle=True,\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            #callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "            initial_epoch=initial_epoch,\n",
    "            # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "            verbose=1)\n",
    "        \n",
    "        for i, layer in enumerate(model.layers):\n",
    "            print(i, layer.name)\n",
    "        \n",
    "        for layer in model.layers[:166]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[166:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        initial_epoch=PRE_TRAIN_EPOCH\n",
    "            \n",
    "    # ### Freeze first layer\n",
    "    # conv_list = [layer for layer in model.layers if isinstance(layer, keras.layers.Conv2D)]\n",
    "    # conv_list[0].trainable = False\n",
    "    # # conv_list[1].trainable = False\n",
    "\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = pth.join(model_path, '{fold:02d}-{epoch:06d}-{val_loss:0.6f}-{loss:0.6f}.hdf5')\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=model_filename, verbose=1, \n",
    "        period=1, save_best_only=True, \n",
    "        monitor='val_loss'\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "\n",
    "    hist = model.fit(\n",
    "        x=train_dataset, #epochs=config['num_epoch'], \n",
    "        #batch_size = BATCH_SIZES[fold],\n",
    "        epochs=EPOCHS[fold], \n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        validation_data=val_dataset, shuffle=True,\n",
    "        callbacks = [get_lr_callback(), checkpointer], #, es], #batch_size=config['batch_size']\n",
    "        initial_epoch=0, #### JUST 0 TO FIXED EPOCH COUNT #initial_epoch,\n",
    "        # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print('Loading best model...')\n",
    "    model.load_weights('fold-%i.h5'%fold)\n",
    "\n",
    "    #K.clear_session()\n",
    "    #del(model)\n",
    "    \n",
    "    chk_name_list = sorted([name for name in os.listdir(model_path) if name != '000000_last.hdf5'])\n",
    "    for chk_name in chk_name_list[:-20]:\n",
    "        os.remove(pth.join(model_path, chk_name))\n",
    "    # clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibXfENT5zvwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ARllmjWGk-"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "u1S7DrvwhFPM"
   },
   "outputs": [],
   "source": [
    "image_feature_description_for_test = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_for_test(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description_for_test)\n",
    "\n",
    "def map_func_for_test(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def resize_and_crop_func_for_test(image):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    #result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # revive\n",
    "    return result_image\n",
    "\n",
    "def post_process_func_for_test(image):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wi2igBp6WSYD"
   },
   "outputs": [],
   "source": [
    "submission_base_path = pth.join(data_base_path, 'submission')\n",
    "os.makedirs(submission_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "selected weight to load= 000006-0.000843-0.000243.hdf5\n",
      "      2/Unknown - 0s 25ms/stepWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_predict_batch_end` time: 0.4566s). Check your callbacks.\n",
      "475/475 [==============================] - 233s 490ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "# for conv_comb, activation, base_channel, \\\n",
    "#     between_type, fc_num, batch_size \\\n",
    "#         in itertools.product(conv_comb_list, activation_list,\n",
    "#                               base_channel_list, between_type_list, fc_list,\n",
    "#                               batch_size_list):\n",
    "#     config['conv']['conv_num'] = conv_comb\n",
    "#     config['conv']['base_channel'] = base_channel\n",
    "#     config['activation'] = activation\n",
    "#     config['between_type'] = between_type\n",
    "#     config['fc']['fc_num'] = fc_num\n",
    "#     config['batch_size'] = batch_size\n",
    "\n",
    "for LEARNING_RATE in [1e-3]: #, 1e-4, 1e-5]: # just once\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "    #base += '_input_{}'.format(config['input_shape'][0])\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(config['batch_size'])\n",
    "    test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "    model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "    print('selected weight to load=', model_chk_name)\n",
    "    initial_epoch = int(model_chk_name.split('-')[0])\n",
    "    model.load_weights(pth.join(model_path, model_chk_name))\n",
    "\n",
    "    preds = model.predict(test_dataset, verbose=1)\n",
    "    \n",
    "    #pred_labels = np.argmax(preds, axis=1)\n",
    "    #pred_probs = np.array([pred[indice] for pred, indice in zip(preds, pred_labels)])\n",
    "    \n",
    "    # argmax --> top3\n",
    "    pred_labels = np.argsort(-preds)\n",
    "    \n",
    "    submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "    submission_df = pd.read_csv(submission_csv_path)\n",
    "    \n",
    "    merged_df = []\n",
    "    \n",
    "    RANK_TO_SAVE = 5\n",
    "    for i in range(RANK_TO_SAVE):\n",
    "        tmp_df = submission_df.copy()\n",
    "        \n",
    "        tmp_labels = pred_labels[:, i]\n",
    "        tmp_df['landmark_id'] = tmp_labels\n",
    "        tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])\n",
    "        merged_df.append(tmp_df)\n",
    "    \n",
    "    submission_df = pd.concat(merged_df)\n",
    "    \n",
    "    #submission_df['landmark_id'] = pred_labels\n",
    "    #submission_df['conf'] = pred_probs\n",
    "\n",
    "    today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "    result_filename = '{}.csv'.format(model_name)\n",
    "    submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "    submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "\n",
    "merged_df = []\n",
    "\n",
    "RANK_TO_SAVE = 1\n",
    "for i in range(RANK_TO_SAVE):\n",
    "    tmp_df = submission_df.copy()\n",
    "\n",
    "    tmp_labels = pred_labels[:, i]\n",
    "    tmp_df['landmark_id'] = tmp_labels\n",
    "    tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])\n",
    "    merged_df.append(tmp_df)\n",
    "\n",
    "submission_df = pd.concat(merged_df)\n",
    "\n",
    "#submission_df['landmark_id'] = pred_labels\n",
    "#submission_df['conf'] = pred_probs\n",
    "\n",
    "today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "result_filename = '{}_top1.csv'.format(model_name)\n",
    "submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMStwUj7nYz9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Training_MobileNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
