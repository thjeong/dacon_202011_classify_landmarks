{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XDnap1jLv8so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as pth\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([324., 576.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([540,960]) * 6/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffY3gSLAvvSs"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = 'MobileNetV2-for-upload'\n",
    "my_model_base = keras.applications.mobilenet_v2\n",
    "my_model = my_model_base.MobileNetV2\n",
    "\n",
    "config = {\n",
    "    'is_zscore':True,\n",
    "    \n",
    "    # 'input_shape': (540, 960, 3),\n",
    "    'aug': {\n",
    "        #'resize': (270, 480),\n",
    "        'resize': (324, 576),\n",
    "    },\n",
    "    # 'input_shape': (224, 360, 3),\n",
    "    #'input_shape': (270, 480, 3),\n",
    "    'input_shape': (270, 480, 3),\n",
    "\n",
    "    'output_activation': 'softmax',\n",
    "    'num_class': 1049,\n",
    "    'output_size': 1049,\n",
    "    \n",
    "    'conv':{\n",
    "        'conv_num': (0), # (3,5,3),\n",
    "        'base_channel': 0, # 4,\n",
    "        'kernel_size': 0, # 3,\n",
    "        'padding':'same',\n",
    "        'stride':'X'\n",
    "    },\n",
    "    'pool':{\n",
    "        'type':'X',\n",
    "        'size':'X',\n",
    "        'stride':'X',\n",
    "        'padding':'same'\n",
    "    },\n",
    "    'fc':{\n",
    "        'fc_num': 0,\n",
    "     },\n",
    "    \n",
    "    'activation':'relu',\n",
    "    \n",
    "    'between_type': 'avg',\n",
    "    \n",
    "    'is_batchnorm': True,\n",
    "    'is_dropout': False,\n",
    "    'dropout_rate': 0.5,\n",
    "    \n",
    "    'batch_size': 32,\n",
    "    'buffer_size': 256,\n",
    "    'loss': 'CategoricalCrossentropy',\n",
    "    \n",
    "    'num_epoch': 10000,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    'random_state': 7777\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "abOw4s0jv6JI"
   },
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['randmark_id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def resize_and_crop_func(image, label):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # crop revived.\n",
    "    return result_image, label\n",
    "\n",
    "def image_aug_func(image, label):\n",
    "    pass\n",
    "    return image, label\n",
    "\n",
    "def post_process_func(image, label):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    onehot_label = tf.one_hot(label, depth=config['num_class'])\n",
    "    return result_image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j1UN3LYJzFgd"
   },
   "outputs": [],
   "source": [
    "data_base_path = pth.join('data', 'public') \n",
    "os.makedirs(data_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ks1l_51cNzLP"
   },
   "outputs": [],
   "source": [
    "category_csv_name = 'category.csv'\n",
    "category_json_name = 'category.json'\n",
    "submission_csv_name = 'sample_submisstion.csv'\n",
    "train_csv_name = 'train.csv'\n",
    "\n",
    "# train_zip_name = 'train.zip'\n",
    "train_tfrecord_name = 'all_train.tfrecords'\n",
    "train_tfrecord_path = pth.join(data_base_path, train_tfrecord_name)\n",
    "val_tfrecord_name = 'all_val.tfrecords'\n",
    "val_tfrecord_path = pth.join(data_base_path, val_tfrecord_name)\n",
    "# test_zip_name = 'test.zip'\n",
    "test_tfrecord_name = 'test.tfrecords'\n",
    "test_tfrecord_path = pth.join(data_base_path, test_tfrecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MaBBHyX0dMig"
   },
   "outputs": [],
   "source": [
    "train_csv_path = pth.join(data_base_path, train_csv_name)\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_dict = {k:v for k, v in train_df.values}\n",
    "\n",
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "# submission_df.head()\n",
    "\n",
    "category_csv_path = pth.join(data_base_path, category_csv_name)\n",
    "category_df = pd.read_csv(category_csv_path)\n",
    "category_dict = {k:v for k, v in category_df.values}\n",
    "# category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/public/all_train.tfrecords'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfrecord_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdng6pk8k0fH"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q9-4T5OMcy1R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, GroupKFold, RepeatedStratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as pth\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import datetime\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv3D, AveragePooling3D, MaxPooling3D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool3D, GlobalAvgPool3D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HBKtUQ9mnKMn"
   },
   "outputs": [],
   "source": [
    "conv_comb_list = []\n",
    "conv_comb_list += [(0,)]\n",
    "\n",
    "base_channel_list = [0]\n",
    "\n",
    "fc_list = [0] # 128, 0\n",
    "\n",
    "# between_type_list = [None, 'avg', 'max']\n",
    "between_type_list = ['avg']\n",
    "\n",
    "batch_size_list = [80]\n",
    "\n",
    "activation_list = ['relu']\n",
    "\n",
    "# len(conv_comb_list), conv_comb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAaKPD3cnKB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WrRPrv1aoOEA"
   },
   "outputs": [],
   "source": [
    "def build_cnn(config):\n",
    "    input_layer = Input(shape=config['input_shape'], name='input_layer')\n",
    "    pret_model = my_model(\n",
    "        input_tensor=input_layer, include_top=False, weights='imagenet', \n",
    "        input_shape=config['input_shape'], pooling=config['between_type'], \n",
    "        classes=config['output_size']\n",
    "    )\n",
    "\n",
    "    pret_model.trainable = False\n",
    "    \n",
    "    x = pret_model.output\n",
    "    \n",
    "    if config['between_type'] == None:\n",
    "        x = Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "    if config['is_dropout']:\n",
    "        x = Dropout(config['dropout_rate'], name='output_dropout')(x)    \n",
    "            \n",
    "    x = Dense(config['output_size'], activation=config['output_activation'], \n",
    "          name='output_fc')(x)\n",
    "#     x = Activation(activation=config['output_activation'], name='output_activation')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x, name='{}'.format(BASE_MODEL_NAME))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d5mZ06q3qAmN",
    "outputId": "edc1edc4-147a-43c3-e8c4-0ae69fa5e59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"MobileNetV2-for-upload\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_layer (InputLayer)                         [(None, 270, 480, 3)]            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)                        (None, 271, 481, 3)              0                 input_layer[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                                   (None, 135, 240, 32)             864               Conv1_pad[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)                    (None, 135, 240, 32)             128               Conv1[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)                                (None, 135, 240, 32)             0                 bn_Conv1[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (DepthwiseConv2D)        (None, 135, 240, 32)             288               Conv1_relu[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (BatchNormalization)  (None, 135, 240, 32)             128               expanded_conv_depthwise[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (ReLU)              (None, 135, 240, 32)             0                 expanded_conv_depthwise_BN[0][0]                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)                   (None, 135, 240, 16)             512               expanded_conv_depthwise_relu[0][0]                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (BatchNormalization)    (None, 135, 240, 16)             64                expanded_conv_project[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)                          (None, 135, 240, 96)             1536              expanded_conv_project_BN[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormalization)           (None, 135, 240, 96)             384               block_1_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)                       (None, 135, 240, 96)             0                 block_1_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)                      (None, 137, 241, 96)             0                 block_1_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseConv2D)              (None, 68, 120, 96)              864               block_1_pad[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNormalization)        (None, 68, 120, 96)              384               block_1_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)                    (None, 68, 120, 96)              0                 block_1_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)                         (None, 68, 120, 24)              2304              block_1_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormalization)          (None, 68, 120, 24)              96                block_1_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)                          (None, 68, 120, 144)             3456              block_1_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormalization)           (None, 68, 120, 144)             576               block_2_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)                       (None, 68, 120, 144)             0                 block_2_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseConv2D)              (None, 68, 120, 144)             1296              block_2_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNormalization)        (None, 68, 120, 144)             576               block_2_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)                    (None, 68, 120, 144)             0                 block_2_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)                         (None, 68, 120, 24)              3456              block_2_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormalization)          (None, 68, 120, 24)              96                block_2_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_2_add (Add)                                (None, 68, 120, 24)              0                 block_1_project_BN[0][0]                          \n",
      "                                                                                                    block_2_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)                          (None, 68, 120, 144)             3456              block_2_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormalization)           (None, 68, 120, 144)             576               block_3_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)                       (None, 68, 120, 144)             0                 block_3_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)                      (None, 69, 121, 144)             0                 block_3_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseConv2D)              (None, 34, 60, 144)              1296              block_3_pad[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNormalization)        (None, 34, 60, 144)              576               block_3_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)                    (None, 34, 60, 144)              0                 block_3_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)                         (None, 34, 60, 32)               4608              block_3_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormalization)          (None, 34, 60, 32)               128               block_3_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)                          (None, 34, 60, 192)              6144              block_3_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormalization)           (None, 34, 60, 192)              768               block_4_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)                       (None, 34, 60, 192)              0                 block_4_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseConv2D)              (None, 34, 60, 192)              1728              block_4_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNormalization)        (None, 34, 60, 192)              768               block_4_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)                    (None, 34, 60, 192)              0                 block_4_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)                         (None, 34, 60, 32)               6144              block_4_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormalization)          (None, 34, 60, 32)               128               block_4_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_4_add (Add)                                (None, 34, 60, 32)               0                 block_3_project_BN[0][0]                          \n",
      "                                                                                                    block_4_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)                          (None, 34, 60, 192)              6144              block_4_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormalization)           (None, 34, 60, 192)              768               block_5_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)                       (None, 34, 60, 192)              0                 block_5_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseConv2D)              (None, 34, 60, 192)              1728              block_5_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNormalization)        (None, 34, 60, 192)              768               block_5_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)                    (None, 34, 60, 192)              0                 block_5_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)                         (None, 34, 60, 32)               6144              block_5_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormalization)          (None, 34, 60, 32)               128               block_5_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_5_add (Add)                                (None, 34, 60, 32)               0                 block_4_add[0][0]                                 \n",
      "                                                                                                    block_5_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)                          (None, 34, 60, 192)              6144              block_5_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormalization)           (None, 34, 60, 192)              768               block_6_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)                       (None, 34, 60, 192)              0                 block_6_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)                      (None, 35, 61, 192)              0                 block_6_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseConv2D)              (None, 17, 30, 192)              1728              block_6_pad[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNormalization)        (None, 17, 30, 192)              768               block_6_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)                    (None, 17, 30, 192)              0                 block_6_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)                         (None, 17, 30, 64)               12288             block_6_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormalization)          (None, 17, 30, 64)               256               block_6_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)                          (None, 17, 30, 384)              24576             block_6_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormalization)           (None, 17, 30, 384)              1536              block_7_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)                       (None, 17, 30, 384)              0                 block_7_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseConv2D)              (None, 17, 30, 384)              3456              block_7_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNormalization)        (None, 17, 30, 384)              1536              block_7_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)                    (None, 17, 30, 384)              0                 block_7_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)                         (None, 17, 30, 64)               24576             block_7_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormalization)          (None, 17, 30, 64)               256               block_7_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_7_add (Add)                                (None, 17, 30, 64)               0                 block_6_project_BN[0][0]                          \n",
      "                                                                                                    block_7_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)                          (None, 17, 30, 384)              24576             block_7_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormalization)           (None, 17, 30, 384)              1536              block_8_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)                       (None, 17, 30, 384)              0                 block_8_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseConv2D)              (None, 17, 30, 384)              3456              block_8_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNormalization)        (None, 17, 30, 384)              1536              block_8_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)                    (None, 17, 30, 384)              0                 block_8_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)                         (None, 17, 30, 64)               24576             block_8_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormalization)          (None, 17, 30, 64)               256               block_8_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_8_add (Add)                                (None, 17, 30, 64)               0                 block_7_add[0][0]                                 \n",
      "                                                                                                    block_8_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)                          (None, 17, 30, 384)              24576             block_8_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormalization)           (None, 17, 30, 384)              1536              block_9_expand[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)                       (None, 17, 30, 384)              0                 block_9_expand_BN[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseConv2D)              (None, 17, 30, 384)              3456              block_9_expand_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNormalization)        (None, 17, 30, 384)              1536              block_9_depthwise[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)                    (None, 17, 30, 384)              0                 block_9_depthwise_BN[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)                         (None, 17, 30, 64)               24576             block_9_depthwise_relu[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormalization)          (None, 17, 30, 64)               256               block_9_project[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_9_add (Add)                                (None, 17, 30, 64)               0                 block_8_add[0][0]                                 \n",
      "                                                                                                    block_9_project_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)                         (None, 17, 30, 384)              24576             block_9_add[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormalization)          (None, 17, 30, 384)              1536              block_10_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)                      (None, 17, 30, 384)              0                 block_10_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseConv2D)             (None, 17, 30, 384)              3456              block_10_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNormalization)       (None, 17, 30, 384)              1536              block_10_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)                   (None, 17, 30, 384)              0                 block_10_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)                        (None, 17, 30, 96)               36864             block_10_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNormalization)         (None, 17, 30, 96)               384               block_10_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)                         (None, 17, 30, 576)              55296             block_10_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormalization)          (None, 17, 30, 576)              2304              block_11_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)                      (None, 17, 30, 576)              0                 block_11_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseConv2D)             (None, 17, 30, 576)              5184              block_11_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNormalization)       (None, 17, 30, 576)              2304              block_11_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)                   (None, 17, 30, 576)              0                 block_11_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)                        (None, 17, 30, 96)               55296             block_11_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNormalization)         (None, 17, 30, 96)               384               block_11_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_11_add (Add)                               (None, 17, 30, 96)               0                 block_10_project_BN[0][0]                         \n",
      "                                                                                                    block_11_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)                         (None, 17, 30, 576)              55296             block_11_add[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormalization)          (None, 17, 30, 576)              2304              block_12_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)                      (None, 17, 30, 576)              0                 block_12_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseConv2D)             (None, 17, 30, 576)              5184              block_12_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNormalization)       (None, 17, 30, 576)              2304              block_12_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)                   (None, 17, 30, 576)              0                 block_12_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)                        (None, 17, 30, 96)               55296             block_12_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNormalization)         (None, 17, 30, 96)               384               block_12_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_12_add (Add)                               (None, 17, 30, 96)               0                 block_11_add[0][0]                                \n",
      "                                                                                                    block_12_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)                         (None, 17, 30, 576)              55296             block_12_add[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormalization)          (None, 17, 30, 576)              2304              block_13_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)                      (None, 17, 30, 576)              0                 block_13_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)                     (None, 19, 31, 576)              0                 block_13_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseConv2D)             (None, 9, 15, 576)               5184              block_13_pad[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNormalization)       (None, 9, 15, 576)               2304              block_13_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)                   (None, 9, 15, 576)               0                 block_13_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)                        (None, 9, 15, 160)               92160             block_13_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNormalization)         (None, 9, 15, 160)               640               block_13_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)                         (None, 9, 15, 960)               153600            block_13_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormalization)          (None, 9, 15, 960)               3840              block_14_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)                      (None, 9, 15, 960)               0                 block_14_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseConv2D)             (None, 9, 15, 960)               8640              block_14_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNormalization)       (None, 9, 15, 960)               3840              block_14_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)                   (None, 9, 15, 960)               0                 block_14_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)                        (None, 9, 15, 160)               153600            block_14_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNormalization)         (None, 9, 15, 160)               640               block_14_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_14_add (Add)                               (None, 9, 15, 160)               0                 block_13_project_BN[0][0]                         \n",
      "                                                                                                    block_14_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)                         (None, 9, 15, 960)               153600            block_14_add[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormalization)          (None, 9, 15, 960)               3840              block_15_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)                      (None, 9, 15, 960)               0                 block_15_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseConv2D)             (None, 9, 15, 960)               8640              block_15_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNormalization)       (None, 9, 15, 960)               3840              block_15_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)                   (None, 9, 15, 960)               0                 block_15_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)                        (None, 9, 15, 160)               153600            block_15_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNormalization)         (None, 9, 15, 160)               640               block_15_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_15_add (Add)                               (None, 9, 15, 160)               0                 block_14_add[0][0]                                \n",
      "                                                                                                    block_15_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)                         (None, 9, 15, 960)               153600            block_15_add[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormalization)          (None, 9, 15, 960)               3840              block_16_expand[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)                      (None, 9, 15, 960)               0                 block_16_expand_BN[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseConv2D)             (None, 9, 15, 960)               8640              block_16_expand_relu[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNormalization)       (None, 9, 15, 960)               3840              block_16_depthwise[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)                   (None, 9, 15, 960)               0                 block_16_depthwise_BN[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)                        (None, 9, 15, 320)               307200            block_16_depthwise_relu[0][0]                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNormalization)         (None, 9, 15, 320)               1280              block_16_project[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                                  (None, 9, 15, 1280)              409600            block_16_project_BN[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)                   (None, 9, 15, 1280)              5120              Conv_1[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_relu (ReLU)                                  (None, 9, 15, 1280)              0                 Conv_1_bn[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "global_average_pooling2d (GlobalAveragePooling2D (None, 1280)                     0                 out_relu[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "output_fc (Dense)                                (None, 1049)                     1343769           global_average_pooling2d[0][0]                    \n",
      "======================================================================================================================================================\n",
      "Total params: 3,601,753\n",
      "Trainable params: 1,343,769\n",
      "Non-trainable params: 2,257,984\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(config)\n",
    "model.summary(line_length=150)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCsZqqHyqAds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-CFjGGnr1iDN"
   },
   "outputs": [],
   "source": [
    "origin_train_len = len(train_df) / 5 * 4\n",
    "origin_val_len = len(train_df) / 5 * 1\n",
    "\n",
    "train_num_steps = int(np.ceil((origin_train_len)/config['batch_size']))\n",
    "val_num_steps = int(np.ceil((origin_val_len)/config['batch_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YzKzI0vXsrJp"
   },
   "outputs": [],
   "source": [
    "model_base_path = data_base_path\n",
    "model_checkpoint_path = pth.join(model_base_path, 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ta_kqsLstQcV",
    "outputId": "760909ad-2f6c-444c-aa85-43ab5e364c6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 50/10000\n",
      "    881/Unknown - 211s 239ms/step - loss: 0.0145 - acc: 0.9961 - precision: 0.9972 - recall: 0.9955 - auc: 0.9998\n",
      "Epoch 00050: val_loss improved from inf to 0.30969, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000050-0.309694-0.014482.hdf5\n",
      "882/882 [==============================] - 262s 297ms/step - loss: 0.0145 - acc: 0.9961 - precision: 0.9972 - recall: 0.9955 - auc: 0.9998 - val_loss: 0.3097 - val_acc: 0.9418 - val_precision: 0.9559 - val_recall: 0.9359 - val_auc: 0.9902\n",
      "Epoch 51/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9968 - precision: 0.9975 - recall: 0.9963 - auc: 0.9998\n",
      "Epoch 00051: val_loss improved from 0.30969 to 0.30647, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000051-0.306475-0.012390.hdf5\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0124 - acc: 0.9968 - precision: 0.9975 - recall: 0.9963 - auc: 0.9998 - val_loss: 0.3065 - val_acc: 0.9449 - val_precision: 0.9580 - val_recall: 0.9399 - val_auc: 0.9900\n",
      "Epoch 52/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977 - precision: 0.9982 - recall: 0.9973 - auc: 0.9999\n",
      "Epoch 00052: val_loss improved from 0.30647 to 0.30260, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000052-0.302596-0.008444.hdf5\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0084 - acc: 0.9977 - precision: 0.9982 - recall: 0.9973 - auc: 0.9999 - val_loss: 0.3026 - val_acc: 0.9435 - val_precision: 0.9577 - val_recall: 0.9388 - val_auc: 0.9904\n",
      "Epoch 53/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9978 - precision: 0.9983 - recall: 0.9974 - auc: 0.9999\n",
      "Epoch 00053: val_loss did not improve from 0.30260\n",
      "882/882 [==============================] - 259s 294ms/step - loss: 0.0084 - acc: 0.9978 - precision: 0.9983 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.3089 - val_acc: 0.9435 - val_precision: 0.9561 - val_recall: 0.9388 - val_auc: 0.9903\n",
      "Epoch 54/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9974 - precision: 0.9980 - recall: 0.9970 - auc: 0.9999\n",
      "Epoch 00054: val_loss improved from 0.30260 to 0.29648, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000054-0.296476-0.009422.hdf5\n",
      "882/882 [==============================] - 260s 295ms/step - loss: 0.0094 - acc: 0.9974 - precision: 0.9980 - recall: 0.9970 - auc: 0.9999 - val_loss: 0.2965 - val_acc: 0.9472 - val_precision: 0.9603 - val_recall: 0.9427 - val_auc: 0.9903\n",
      "Epoch 55/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9976 - precision: 0.9982 - recall: 0.9972 - auc: 0.9999\n",
      "Epoch 00055: val_loss did not improve from 0.29648\n",
      "882/882 [==============================] - 259s 294ms/step - loss: 0.0097 - acc: 0.9976 - precision: 0.9982 - recall: 0.9972 - auc: 0.9999 - val_loss: 0.2977 - val_acc: 0.9463 - val_precision: 0.9583 - val_recall: 0.9423 - val_auc: 0.9907\n",
      "Epoch 56/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9977 - precision: 0.9982 - recall: 0.9974 - auc: 0.9999\n",
      "Epoch 00056: val_loss did not improve from 0.29648\n",
      "882/882 [==============================] - 259s 294ms/step - loss: 0.0088 - acc: 0.9977 - precision: 0.9982 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.2977 - val_acc: 0.9456 - val_precision: 0.9591 - val_recall: 0.9408 - val_auc: 0.9903\n",
      "Epoch 57/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9980 - precision: 0.9986 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 00057: val_loss improved from 0.29648 to 0.29185, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000057-0.291853-0.007286.hdf5\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0073 - acc: 0.9980 - precision: 0.9986 - recall: 0.9977 - auc: 0.9999 - val_loss: 0.2919 - val_acc: 0.9484 - val_precision: 0.9606 - val_recall: 0.9446 - val_auc: 0.9904\n",
      "Epoch 58/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9980 - precision: 0.9984 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 00058: val_loss improved from 0.29185 to 0.28756, saving model to data/public/checkpoint/MobileNetV2-for-upload_resize_324_input_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000058-0.287558-0.007865.hdf5\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0079 - acc: 0.9980 - precision: 0.9984 - recall: 0.9977 - auc: 0.9999 - val_loss: 0.2876 - val_acc: 0.9468 - val_precision: 0.9595 - val_recall: 0.9428 - val_auc: 0.9906\n",
      "Epoch 59/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980 - precision: 0.9985 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 00059: val_loss did not improve from 0.28756\n",
      "882/882 [==============================] - 260s 295ms/step - loss: 0.0080 - acc: 0.9980 - precision: 0.9985 - recall: 0.9977 - auc: 0.9999 - val_loss: 0.2988 - val_acc: 0.9455 - val_precision: 0.9570 - val_recall: 0.9425 - val_auc: 0.9899\n",
      "Epoch 60/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9984 - precision: 0.9988 - recall: 0.9981 - auc: 0.9999\n",
      "Epoch 00060: val_loss did not improve from 0.28756\n",
      "882/882 [==============================] - 259s 294ms/step - loss: 0.0061 - acc: 0.9984 - precision: 0.9988 - recall: 0.9981 - auc: 0.9999 - val_loss: 0.3060 - val_acc: 0.9459 - val_precision: 0.9579 - val_recall: 0.9420 - val_auc: 0.9903\n",
      "Epoch 61/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9982 - precision: 0.9986 - recall: 0.9979 - auc: 1.0000\n",
      "Epoch 00061: val_loss did not improve from 0.28756\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0067 - acc: 0.9982 - precision: 0.9986 - recall: 0.9979 - auc: 1.0000 - val_loss: 0.3026 - val_acc: 0.9474 - val_precision: 0.9587 - val_recall: 0.9436 - val_auc: 0.9903\n",
      "Epoch 62/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9983 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000\n",
      "Epoch 00062: val_loss did not improve from 0.28756\n",
      "882/882 [==============================] - 261s 296ms/step - loss: 0.0061 - acc: 0.9983 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - val_loss: 0.3076 - val_acc: 0.9476 - val_precision: 0.9590 - val_recall: 0.9435 - val_auc: 0.9896\n",
      "Epoch 63/10000\n",
      " 86/882 [=>............................] - ETA: 3:09 - loss: 0.0062 - acc: 0.9984 - precision: 0.9985 - recall: 0.9983 - auc: 0.9999"
     ]
    }
   ],
   "source": [
    "for conv_comb, activation, base_channel, \\\n",
    "    between_type, fc_num, batch_size \\\n",
    "        in itertools.product(conv_comb_list, activation_list,\n",
    "                              base_channel_list, between_type_list, fc_list,\n",
    "                              batch_size_list):\n",
    "    config['conv']['conv_num'] = conv_comb\n",
    "    config['conv']['base_channel'] = base_channel\n",
    "    config['activation'] = activation\n",
    "    config['between_type'] = between_type\n",
    "    config['fc']['fc_num'] = fc_num\n",
    "    config['batch_size'] = batch_size\n",
    "\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "    base += '_input_{}'.format(config['input_shape'][0])\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # dataset = dataset.cache()\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(config['buffer_size'])\n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.TFRecordDataset(val_tfrecord_path, compression_type='GZIP')\n",
    "    val_dataset = val_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.shuffle(config['buffer_size'])\n",
    "    val_dataset = val_dataset.batch(config['batch_size'])\n",
    "    val_dataset = val_dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.cache()\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "#     model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "#                   metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    if pth.isdir(model_path) and len([_ for _ in os.listdir(model_path) if _.endswith('hdf5')]) >= 1:\n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "        model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "        initial_epoch = int(model_chk_name.split('-')[0])\n",
    "        model.load_weights(pth.join(model_path, model_chk_name))\n",
    "    else:\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                     metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        model.fit(\n",
    "            x=dataset, epochs=6, # train only top layers for just a few epochs.\n",
    "            validation_data=val_dataset, shuffle=True,\n",
    "            #callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "            initial_epoch=initial_epoch,\n",
    "            # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "            verbose=1)\n",
    "        \n",
    "        for i, layer in enumerate(model.layers):\n",
    "            print(i, layer.name)\n",
    "        \n",
    "        for layer in model.layers[:135]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[135:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        initial_epoch=6\n",
    "            \n",
    "    # ### Freeze first layer\n",
    "    # conv_list = [layer for layer in model.layers if isinstance(layer, keras.layers.Conv2D)]\n",
    "    # conv_list[0].trainable = False\n",
    "    # # conv_list[1].trainable = False\n",
    "\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = pth.join(model_path, '{epoch:06d}-{val_loss:0.6f}-{loss:0.6f}.hdf5')\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=model_filename, verbose=1, \n",
    "        period=1, save_best_only=True, \n",
    "        monitor='val_loss'\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "\n",
    "    hist = model.fit(\n",
    "        x=dataset, epochs=config['num_epoch'], \n",
    "        validation_data=val_dataset, shuffle=True,\n",
    "        callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "        initial_epoch=initial_epoch,\n",
    "        # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model_analysis_path = model_path.replace('checkpoint', 'analysis')\n",
    "    visualization_path = pth.join(model_analysis_path,'visualization')\n",
    "    os.makedirs(visualization_path, exist_ok=True)\n",
    "    \n",
    "    print()\n",
    "    # clear_output()        \n",
    "    for each_label in ['loss', 'acc', 'precision', 'recall', 'auc']:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(hist.history[each_label], 'g', label='train_{}'.format(each_label))\n",
    "        ax.plot(hist.history['val_{}'.format(each_label)], 'r', label='val_{}'.format(each_label))\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.legend(loc='upper left')\n",
    "        if not each_label == 'loss':\n",
    "            plt.ylim(0, 1)\n",
    "        plt.show()\n",
    "        filename = 'learning_curve_{}'.format(each_label)\n",
    "#             fig.savefig(pth.join(visualization_path, filename), transparent=True)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "\n",
    "    np.savez_compressed(pth.join(visualization_path, 'learning_curve'), \n",
    "                        loss=hist.history['loss'], \n",
    "                        val_loss=hist.history['val_loss'],\n",
    "                        acc=hist.history['acc'], \n",
    "                        val_acc=hist.history['val_acc'],\n",
    "                        precision=hist.history['precision'], \n",
    "                        vaval_precisionl_mae=hist.history['val_precision'],  \n",
    "                        recall=hist.history['recall'],\n",
    "                        val_recall=hist.history['val_recall'],\n",
    "                        auc=hist.history['auc'],\n",
    "                        val_auc=hist.history['val_auc']\n",
    "                        )\n",
    "\n",
    "    model.save(pth.join(model_path, '000000_last.hdf5'))\n",
    "    K.clear_session()\n",
    "    del(model)\n",
    "    \n",
    "    model_analysis_base_path = pth.join(model_base_path, 'analysis', model_name) \n",
    "    with open(pth.join(model_analysis_base_path, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "    chk_name_list = sorted([name for name in os.listdir(model_path) if name != '000000_last.hdf5'])\n",
    "    for chk_name in chk_name_list[:-5]:\n",
    "        os.remove(pth.join(model_path, chk_name))\n",
    "    # clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibXfENT5zvwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ARllmjWGk-"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "u1S7DrvwhFPM"
   },
   "outputs": [],
   "source": [
    "image_feature_description_for_test = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_for_test(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description_for_test)\n",
    "\n",
    "def map_func_for_test(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def resize_and_crop_func_for_test(image):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # revive\n",
    "    return result_image\n",
    "\n",
    "def post_process_func_for_test(image):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wi2igBp6WSYD"
   },
   "outputs": [],
   "source": [
    "submission_base_path = pth.join(data_base_path, 'submission')\n",
    "os.makedirs(submission_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "      1/Unknown - 0s 48us/stepWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_predict_batch_end` time: 0.1893s). Check your callbacks.\n",
      "475/475 [==============================] - 102s 215ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for conv_comb, activation, base_channel, \\\n",
    "    between_type, fc_num, batch_size \\\n",
    "        in itertools.product(conv_comb_list, activation_list,\n",
    "                              base_channel_list, between_type_list, fc_list,\n",
    "                              batch_size_list):\n",
    "    config['conv']['conv_num'] = conv_comb\n",
    "    config['conv']['base_channel'] = base_channel\n",
    "    config['activation'] = activation\n",
    "    config['between_type'] = between_type\n",
    "    config['fc']['fc_num'] = fc_num\n",
    "    config['batch_size'] = batch_size\n",
    "\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(config['batch_size'])\n",
    "    test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "    model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "    initial_epoch = int(model_chk_name.split('-')[0])\n",
    "    model.load_weights(pth.join(model_path, model_chk_name))\n",
    "\n",
    "    preds = model.predict(test_dataset, verbose=1)\n",
    "    \n",
    "    #pred_labels = np.argmax(preds, axis=1)\n",
    "    #pred_probs = np.array([pred[indice] for pred, indice in zip(preds, pred_labels)])\n",
    "    \n",
    "    # argmax --> top3\n",
    "    pred_labels = np.argsort(-preds)\n",
    "    \n",
    "    submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "    submission_df = pd.read_csv(submission_csv_path)\n",
    "    \n",
    "    merged_df = []\n",
    "    \n",
    "    RANK_TO_SAVE = 3\n",
    "    for i in range(RANK_TO_SAVE):\n",
    "        tmp_df = submission_df.copy()\n",
    "        \n",
    "        tmp_labels = pred_labels[:, i]\n",
    "        tmp_df['landmark_id'] = tmp_labels\n",
    "        tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])\n",
    "        merged_df.append(tmp_df)\n",
    "    \n",
    "    submission_df = pd.concat(merged_df)\n",
    "    \n",
    "    #submission_df['landmark_id'] = pred_labels\n",
    "    #submission_df['conf'] = pred_probs\n",
    "\n",
    "    today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "    result_filename = '{}.csv'.format(model_name)\n",
    "    submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "    submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Trashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "71z9_wKaMPTJ",
    "outputId": "aae36664-100b-46f1-ebd1-25a3804e4b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2-for-upload_resize_405_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[7680,205,205] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobileNetV2-for-upload/block_1_pad/Pad (defined at <ipython-input-16-1fb31696ff24>:58) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_6281]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1fb31696ff24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_chk_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[7680,205,205] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobileNetV2-for-upload/block_1_pad/Pad (defined at <ipython-input-16-1fb31696ff24>:58) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_6281]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for conv_comb, activation, base_channel, \\\n",
    "    between_type, fc_num, batch_size \\\n",
    "        in itertools.product(conv_comb_list, activation_list,\n",
    "                              base_channel_list, between_type_list, fc_list,\n",
    "                              batch_size_list):\n",
    "    config['conv']['conv_num'] = conv_comb\n",
    "    config['conv']['base_channel'] = base_channel\n",
    "    config['activation'] = activation\n",
    "    config['between_type'] = between_type\n",
    "    config['fc']['fc_num'] = fc_num\n",
    "    config['batch_size'] = batch_size\n",
    "\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "    base += '_input_{}'.format(config['input_shape'][0])\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(config['batch_size'])\n",
    "    test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "    model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "    initial_epoch = int(model_chk_name.split('-')[0])\n",
    "    model.load_weights(pth.join(model_path, model_chk_name))\n",
    "\n",
    "    preds = model.predict(test_dataset, verbose=1)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "    pred_probs = np.array([pred[indice] for pred, indice in zip(preds, pred_labels)])\n",
    "\n",
    "    submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "    submission_df = pd.read_csv(submission_csv_path)\n",
    "\n",
    "    submission_df['landmark_id'] = pred_labels\n",
    "    submission_df['conf'] = pred_probs\n",
    "\n",
    "    today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "    result_filename = '{}.csv'.format(model_name)\n",
    "    submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "    submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMStwUj7nYz9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Training_MobileNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
