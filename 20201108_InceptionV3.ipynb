{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XDnap1jLv8so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as pth\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffY3gSLAvvSs"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = 'InceptionV3-for-upload'\n",
    "my_model_base = keras.applications.inception_v3\n",
    "my_model = my_model_base.InceptionV3\n",
    "\n",
    "config = {\n",
    "    'is_zscore':True,\n",
    "    \n",
    "    # 'input_shape': (540, 960, 3),\n",
    "    'aug': {\n",
    "        #'resize': (270, 480),\n",
    "        'resize': (297, 528),\n",
    "    },\n",
    "    # 'input_shape': (224, 360, 3),\n",
    "    #'input_shape': (270, 480, 3),\n",
    "    'input_shape': (270, 480, 3),\n",
    "\n",
    "    'output_activation': 'softmax',\n",
    "    'num_class': 1049,\n",
    "    'output_size': 1049,\n",
    "    \n",
    "    'conv':{\n",
    "        'conv_num': (0), # (3,5,3),\n",
    "        'base_channel': 0, # 4,\n",
    "        'kernel_size': 0, # 3,\n",
    "        'padding':'same',\n",
    "        'stride':'X'\n",
    "    },\n",
    "    'pool':{\n",
    "        'type':'X',\n",
    "        'size':'X',\n",
    "        'stride':'X',\n",
    "        'padding':'same'\n",
    "    },\n",
    "    'fc':{\n",
    "        'fc_num': 0,\n",
    "     },\n",
    "    \n",
    "    'activation':'relu',\n",
    "    \n",
    "    'between_type': 'avg',\n",
    "    \n",
    "    'is_batchnorm': True,\n",
    "    'is_dropout': False,\n",
    "    'dropout_rate': 0.5,\n",
    "    \n",
    "    'add_dense':True,\n",
    "    'dense_size': 1024,\n",
    "    \n",
    "    'batch_size': 64, #64,\n",
    "    'buffer_size': 256, #256,\n",
    "    'loss': 'CategoricalCrossentropy',\n",
    "    \n",
    "    'num_epoch': 10000,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    'random_state': 7777\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "abOw4s0jv6JI"
   },
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['randmark_id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def resize_and_crop_func(image, label):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)\n",
    "    return result_image, label\n",
    "\n",
    "def image_aug_func(image, label):\n",
    "    pass\n",
    "    return image, label\n",
    "\n",
    "def post_process_func(image, label):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    onehot_label = tf.one_hot(label, depth=config['num_class'])\n",
    "    return result_image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j1UN3LYJzFgd"
   },
   "outputs": [],
   "source": [
    "data_base_path = pth.join('data', 'public')  \n",
    "os.makedirs(data_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ks1l_51cNzLP"
   },
   "outputs": [],
   "source": [
    "category_csv_name = 'category.csv'\n",
    "category_json_name = 'category.json'\n",
    "submission_csv_name = 'sample_submisstion.csv'\n",
    "train_csv_name = 'train.csv'\n",
    "\n",
    "# train_zip_name = 'train.zip'\n",
    "train_tfrecord_name = 'all_train.tfrecords'\n",
    "train_tfrecord_path = pth.join(data_base_path, train_tfrecord_name)\n",
    "val_tfrecord_name = 'all_val.tfrecords'\n",
    "val_tfrecord_path = pth.join(data_base_path, val_tfrecord_name)\n",
    "# test_zip_name = 'test.zip'\n",
    "test_tfrecord_name = 'test.tfrecords'\n",
    "test_tfrecord_path = pth.join(data_base_path, test_tfrecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MaBBHyX0dMig"
   },
   "outputs": [],
   "source": [
    "train_csv_path = pth.join(data_base_path, train_csv_name)\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_dict = {k:v for k, v in train_df.values}\n",
    "\n",
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "# submission_df.head()\n",
    "\n",
    "category_csv_path = pth.join(data_base_path, category_csv_name)\n",
    "category_df = pd.read_csv(category_csv_path)\n",
    "category_dict = {k:v for k, v in category_df.values}\n",
    "# category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/public/all_train.tfrecords'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfrecord_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdng6pk8k0fH"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q9-4T5OMcy1R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, GroupKFold, RepeatedStratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as pth\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import datetime\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv3D, AveragePooling3D, MaxPooling3D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool3D, GlobalAvgPool3D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HBKtUQ9mnKMn"
   },
   "outputs": [],
   "source": [
    "conv_comb_list = []\n",
    "conv_comb_list += [(0,)]\n",
    "\n",
    "base_channel_list = [0]\n",
    "\n",
    "fc_list = [0] # 128, 0\n",
    "\n",
    "# between_type_list = [None, 'avg', 'max']\n",
    "between_type_list = ['avg']\n",
    "\n",
    "batch_size_list = [80]\n",
    "\n",
    "activation_list = ['relu']\n",
    "\n",
    "# len(conv_comb_list), conv_comb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAaKPD3cnKB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WrRPrv1aoOEA"
   },
   "outputs": [],
   "source": [
    "def build_cnn(config):\n",
    "    input_layer = Input(shape=config['input_shape'], name='input_layer')\n",
    "    pret_model = my_model(\n",
    "        input_tensor=input_layer, include_top=False, weights='imagenet', \n",
    "        input_shape=config['input_shape'], pooling=config['between_type'], \n",
    "        classes=config['output_size']\n",
    "    )\n",
    "\n",
    "    pret_model.trainable = False\n",
    "    \n",
    "    x = pret_model.output\n",
    "    \n",
    "    if config['between_type'] == None:\n",
    "        x = Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "    if config['is_dropout']:\n",
    "        x = Dropout(config['dropout_rate'], name='output_dropout')(x)    \n",
    "\n",
    "    if config['add_dense']:\n",
    "        x = Dense(config['dense_size'], activation=config['activation'],\n",
    "                    name='dense_layer')(x)\n",
    "\n",
    "    x = Dense(config['output_size'], activation=config['output_activation'], \n",
    "          name='output_fc')(x)\n",
    "#     x = Activation(activation=config['output_activation'], name='output_activation')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x, name='{}'.format(BASE_MODEL_NAME))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d5mZ06q3qAmN",
    "outputId": "edc1edc4-147a-43c3-e8c4-0ae69fa5e59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer\n",
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n",
      "4 conv2d_1\n",
      "5 batch_normalization_1\n",
      "6 activation_1\n",
      "7 conv2d_2\n",
      "8 batch_normalization_2\n",
      "9 activation_2\n",
      "10 max_pooling2d\n",
      "11 conv2d_3\n",
      "12 batch_normalization_3\n",
      "13 activation_3\n",
      "14 conv2d_4\n",
      "15 batch_normalization_4\n",
      "16 activation_4\n",
      "17 max_pooling2d_1\n",
      "18 conv2d_8\n",
      "19 batch_normalization_8\n",
      "20 activation_8\n",
      "21 conv2d_6\n",
      "22 conv2d_9\n",
      "23 batch_normalization_6\n",
      "24 batch_normalization_9\n",
      "25 activation_6\n",
      "26 activation_9\n",
      "27 average_pooling2d\n",
      "28 conv2d_5\n",
      "29 conv2d_7\n",
      "30 conv2d_10\n",
      "31 conv2d_11\n",
      "32 batch_normalization_5\n",
      "33 batch_normalization_7\n",
      "34 batch_normalization_10\n",
      "35 batch_normalization_11\n",
      "36 activation_5\n",
      "37 activation_7\n",
      "38 activation_10\n",
      "39 activation_11\n",
      "40 mixed0\n",
      "41 conv2d_15\n",
      "42 batch_normalization_15\n",
      "43 activation_15\n",
      "44 conv2d_13\n",
      "45 conv2d_16\n",
      "46 batch_normalization_13\n",
      "47 batch_normalization_16\n",
      "48 activation_13\n",
      "49 activation_16\n",
      "50 average_pooling2d_1\n",
      "51 conv2d_12\n",
      "52 conv2d_14\n",
      "53 conv2d_17\n",
      "54 conv2d_18\n",
      "55 batch_normalization_12\n",
      "56 batch_normalization_14\n",
      "57 batch_normalization_17\n",
      "58 batch_normalization_18\n",
      "59 activation_12\n",
      "60 activation_14\n",
      "61 activation_17\n",
      "62 activation_18\n",
      "63 mixed1\n",
      "64 conv2d_22\n",
      "65 batch_normalization_22\n",
      "66 activation_22\n",
      "67 conv2d_20\n",
      "68 conv2d_23\n",
      "69 batch_normalization_20\n",
      "70 batch_normalization_23\n",
      "71 activation_20\n",
      "72 activation_23\n",
      "73 average_pooling2d_2\n",
      "74 conv2d_19\n",
      "75 conv2d_21\n",
      "76 conv2d_24\n",
      "77 conv2d_25\n",
      "78 batch_normalization_19\n",
      "79 batch_normalization_21\n",
      "80 batch_normalization_24\n",
      "81 batch_normalization_25\n",
      "82 activation_19\n",
      "83 activation_21\n",
      "84 activation_24\n",
      "85 activation_25\n",
      "86 mixed2\n",
      "87 conv2d_27\n",
      "88 batch_normalization_27\n",
      "89 activation_27\n",
      "90 conv2d_28\n",
      "91 batch_normalization_28\n",
      "92 activation_28\n",
      "93 conv2d_26\n",
      "94 conv2d_29\n",
      "95 batch_normalization_26\n",
      "96 batch_normalization_29\n",
      "97 activation_26\n",
      "98 activation_29\n",
      "99 max_pooling2d_2\n",
      "100 mixed3\n",
      "101 conv2d_34\n",
      "102 batch_normalization_34\n",
      "103 activation_34\n",
      "104 conv2d_35\n",
      "105 batch_normalization_35\n",
      "106 activation_35\n",
      "107 conv2d_31\n",
      "108 conv2d_36\n",
      "109 batch_normalization_31\n",
      "110 batch_normalization_36\n",
      "111 activation_31\n",
      "112 activation_36\n",
      "113 conv2d_32\n",
      "114 conv2d_37\n",
      "115 batch_normalization_32\n",
      "116 batch_normalization_37\n",
      "117 activation_32\n",
      "118 activation_37\n",
      "119 average_pooling2d_3\n",
      "120 conv2d_30\n",
      "121 conv2d_33\n",
      "122 conv2d_38\n",
      "123 conv2d_39\n",
      "124 batch_normalization_30\n",
      "125 batch_normalization_33\n",
      "126 batch_normalization_38\n",
      "127 batch_normalization_39\n",
      "128 activation_30\n",
      "129 activation_33\n",
      "130 activation_38\n",
      "131 activation_39\n",
      "132 mixed4\n",
      "133 conv2d_44\n",
      "134 batch_normalization_44\n",
      "135 activation_44\n",
      "136 conv2d_45\n",
      "137 batch_normalization_45\n",
      "138 activation_45\n",
      "139 conv2d_41\n",
      "140 conv2d_46\n",
      "141 batch_normalization_41\n",
      "142 batch_normalization_46\n",
      "143 activation_41\n",
      "144 activation_46\n",
      "145 conv2d_42\n",
      "146 conv2d_47\n",
      "147 batch_normalization_42\n",
      "148 batch_normalization_47\n",
      "149 activation_42\n",
      "150 activation_47\n",
      "151 average_pooling2d_4\n",
      "152 conv2d_40\n",
      "153 conv2d_43\n",
      "154 conv2d_48\n",
      "155 conv2d_49\n",
      "156 batch_normalization_40\n",
      "157 batch_normalization_43\n",
      "158 batch_normalization_48\n",
      "159 batch_normalization_49\n",
      "160 activation_40\n",
      "161 activation_43\n",
      "162 activation_48\n",
      "163 activation_49\n",
      "164 mixed5\n",
      "165 conv2d_54\n",
      "166 batch_normalization_54\n",
      "167 activation_54\n",
      "168 conv2d_55\n",
      "169 batch_normalization_55\n",
      "170 activation_55\n",
      "171 conv2d_51\n",
      "172 conv2d_56\n",
      "173 batch_normalization_51\n",
      "174 batch_normalization_56\n",
      "175 activation_51\n",
      "176 activation_56\n",
      "177 conv2d_52\n",
      "178 conv2d_57\n",
      "179 batch_normalization_52\n",
      "180 batch_normalization_57\n",
      "181 activation_52\n",
      "182 activation_57\n",
      "183 average_pooling2d_5\n",
      "184 conv2d_50\n",
      "185 conv2d_53\n",
      "186 conv2d_58\n",
      "187 conv2d_59\n",
      "188 batch_normalization_50\n",
      "189 batch_normalization_53\n",
      "190 batch_normalization_58\n",
      "191 batch_normalization_59\n",
      "192 activation_50\n",
      "193 activation_53\n",
      "194 activation_58\n",
      "195 activation_59\n",
      "196 mixed6\n",
      "197 conv2d_64\n",
      "198 batch_normalization_64\n",
      "199 activation_64\n",
      "200 conv2d_65\n",
      "201 batch_normalization_65\n",
      "202 activation_65\n",
      "203 conv2d_61\n",
      "204 conv2d_66\n",
      "205 batch_normalization_61\n",
      "206 batch_normalization_66\n",
      "207 activation_61\n",
      "208 activation_66\n",
      "209 conv2d_62\n",
      "210 conv2d_67\n",
      "211 batch_normalization_62\n",
      "212 batch_normalization_67\n",
      "213 activation_62\n",
      "214 activation_67\n",
      "215 average_pooling2d_6\n",
      "216 conv2d_60\n",
      "217 conv2d_63\n",
      "218 conv2d_68\n",
      "219 conv2d_69\n",
      "220 batch_normalization_60\n",
      "221 batch_normalization_63\n",
      "222 batch_normalization_68\n",
      "223 batch_normalization_69\n",
      "224 activation_60\n",
      "225 activation_63\n",
      "226 activation_68\n",
      "227 activation_69\n",
      "228 mixed7\n",
      "229 conv2d_72\n",
      "230 batch_normalization_72\n",
      "231 activation_72\n",
      "232 conv2d_73\n",
      "233 batch_normalization_73\n",
      "234 activation_73\n",
      "235 conv2d_70\n",
      "236 conv2d_74\n",
      "237 batch_normalization_70\n",
      "238 batch_normalization_74\n",
      "239 activation_70\n",
      "240 activation_74\n",
      "241 conv2d_71\n",
      "242 conv2d_75\n",
      "243 batch_normalization_71\n",
      "244 batch_normalization_75\n",
      "245 activation_71\n",
      "246 activation_75\n",
      "247 max_pooling2d_3\n",
      "248 mixed8\n",
      "249 conv2d_80\n",
      "250 batch_normalization_80\n",
      "251 activation_80\n",
      "252 conv2d_77\n",
      "253 conv2d_81\n",
      "254 batch_normalization_77\n",
      "255 batch_normalization_81\n",
      "256 activation_77\n",
      "257 activation_81\n",
      "258 conv2d_78\n",
      "259 conv2d_79\n",
      "260 conv2d_82\n",
      "261 conv2d_83\n",
      "262 average_pooling2d_7\n",
      "263 conv2d_76\n",
      "264 batch_normalization_78\n",
      "265 batch_normalization_79\n",
      "266 batch_normalization_82\n",
      "267 batch_normalization_83\n",
      "268 conv2d_84\n",
      "269 batch_normalization_76\n",
      "270 activation_78\n",
      "271 activation_79\n",
      "272 activation_82\n",
      "273 activation_83\n",
      "274 batch_normalization_84\n",
      "275 activation_76\n",
      "276 mixed9_0\n",
      "277 concatenate\n",
      "278 activation_84\n",
      "279 mixed9\n",
      "280 conv2d_89\n",
      "281 batch_normalization_89\n",
      "282 activation_89\n",
      "283 conv2d_86\n",
      "284 conv2d_90\n",
      "285 batch_normalization_86\n",
      "286 batch_normalization_90\n",
      "287 activation_86\n",
      "288 activation_90\n",
      "289 conv2d_87\n",
      "290 conv2d_88\n",
      "291 conv2d_91\n",
      "292 conv2d_92\n",
      "293 average_pooling2d_8\n",
      "294 conv2d_85\n",
      "295 batch_normalization_87\n",
      "296 batch_normalization_88\n",
      "297 batch_normalization_91\n",
      "298 batch_normalization_92\n",
      "299 conv2d_93\n",
      "300 batch_normalization_85\n",
      "301 activation_87\n",
      "302 activation_88\n",
      "303 activation_91\n",
      "304 activation_92\n",
      "305 batch_normalization_93\n",
      "306 activation_85\n",
      "307 mixed9_1\n",
      "308 concatenate_1\n",
      "309 activation_93\n",
      "310 mixed10\n",
      "311 global_average_pooling2d\n",
      "312 dense_layer\n",
      "313 output_fc\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(config)\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)\n",
    "#model.summary(line_length=150)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCsZqqHyqAds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-CFjGGnr1iDN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102 276\n"
     ]
    }
   ],
   "source": [
    "origin_train_len = len(train_df) / 5 * 4\n",
    "origin_val_len = len(train_df) / 5 * 1\n",
    "\n",
    "train_num_steps = int(np.ceil((origin_train_len)/config['batch_size']))\n",
    "val_num_steps = int(np.ceil((origin_val_len)/config['batch_size']))\n",
    "\n",
    "print(train_num_steps, val_num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YzKzI0vXsrJp"
   },
   "outputs": [],
   "source": [
    "model_base_path = data_base_path\n",
    "model_checkpoint_path = pth.join(model_base_path, 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ta_kqsLstQcV",
    "outputId": "760909ad-2f6c-444c-aa85-43ab5e364c6b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "Epoch 1/6\n",
      "882/882 [==============================] - 491s 556ms/step - loss: 4.7238 - acc: 0.1910 - precision: 0.8848 - recall: 0.0427 - auc: 0.7656 - val_loss: 3.4010 - val_acc: 0.3357 - val_precision: 0.7900 - val_recall: 0.1401 - val_auc: 0.8887\n",
      "Epoch 2/6\n",
      "882/882 [==============================] - 488s 553ms/step - loss: 2.4036 - acc: 0.5109 - precision: 0.8809 - recall: 0.3208 - auc: 0.9334 - val_loss: 4.3772 - val_acc: 0.2632 - val_precision: 0.3251 - val_recall: 0.1883 - val_auc: 0.8228\n",
      "Epoch 3/6\n",
      "882/882 [==============================] - 489s 554ms/step - loss: 1.7844 - acc: 0.6210 - precision: 0.8774 - recall: 0.4867 - auc: 0.9524 - val_loss: 2.2026 - val_acc: 0.5559 - val_precision: 0.7977 - val_recall: 0.4504 - val_auc: 0.9297\n",
      "Epoch 4/6\n",
      "882/882 [==============================] - 490s 555ms/step - loss: 1.4776 - acc: 0.6777 - precision: 0.8798 - recall: 0.5743 - auc: 0.9614 - val_loss: 4.6735 - val_acc: 0.3017 - val_precision: 0.3248 - val_recall: 0.2620 - val_auc: 0.8121\n",
      "Epoch 5/6\n",
      "882/882 [==============================] - 488s 554ms/step - loss: 1.2969 - acc: 0.7118 - precision: 0.8815 - recall: 0.6276 - auc: 0.9662 - val_loss: 1.6003 - val_acc: 0.6667 - val_precision: 0.8495 - val_recall: 0.5915 - val_auc: 0.9520\n",
      "Epoch 6/6\n",
      "882/882 [==============================] - 490s 555ms/step - loss: 1.1644 - acc: 0.7381 - precision: 0.8840 - recall: 0.6648 - auc: 0.9697 - val_loss: 2.2090 - val_acc: 0.5694 - val_precision: 0.6934 - val_recall: 0.5120 - val_auc: 0.9225\n",
      "0 input_layer\n",
      "1 conv2d_94\n",
      "2 batch_normalization_94\n",
      "3 activation_94\n",
      "4 conv2d_95\n",
      "5 batch_normalization_95\n",
      "6 activation_95\n",
      "7 conv2d_96\n",
      "8 batch_normalization_96\n",
      "9 activation_96\n",
      "10 max_pooling2d_4\n",
      "11 conv2d_97\n",
      "12 batch_normalization_97\n",
      "13 activation_97\n",
      "14 conv2d_98\n",
      "15 batch_normalization_98\n",
      "16 activation_98\n",
      "17 max_pooling2d_5\n",
      "18 conv2d_102\n",
      "19 batch_normalization_102\n",
      "20 activation_102\n",
      "21 conv2d_100\n",
      "22 conv2d_103\n",
      "23 batch_normalization_100\n",
      "24 batch_normalization_103\n",
      "25 activation_100\n",
      "26 activation_103\n",
      "27 average_pooling2d_9\n",
      "28 conv2d_99\n",
      "29 conv2d_101\n",
      "30 conv2d_104\n",
      "31 conv2d_105\n",
      "32 batch_normalization_99\n",
      "33 batch_normalization_101\n",
      "34 batch_normalization_104\n",
      "35 batch_normalization_105\n",
      "36 activation_99\n",
      "37 activation_101\n",
      "38 activation_104\n",
      "39 activation_105\n",
      "40 mixed0\n",
      "41 conv2d_109\n",
      "42 batch_normalization_109\n",
      "43 activation_109\n",
      "44 conv2d_107\n",
      "45 conv2d_110\n",
      "46 batch_normalization_107\n",
      "47 batch_normalization_110\n",
      "48 activation_107\n",
      "49 activation_110\n",
      "50 average_pooling2d_10\n",
      "51 conv2d_106\n",
      "52 conv2d_108\n",
      "53 conv2d_111\n",
      "54 conv2d_112\n",
      "55 batch_normalization_106\n",
      "56 batch_normalization_108\n",
      "57 batch_normalization_111\n",
      "58 batch_normalization_112\n",
      "59 activation_106\n",
      "60 activation_108\n",
      "61 activation_111\n",
      "62 activation_112\n",
      "63 mixed1\n",
      "64 conv2d_116\n",
      "65 batch_normalization_116\n",
      "66 activation_116\n",
      "67 conv2d_114\n",
      "68 conv2d_117\n",
      "69 batch_normalization_114\n",
      "70 batch_normalization_117\n",
      "71 activation_114\n",
      "72 activation_117\n",
      "73 average_pooling2d_11\n",
      "74 conv2d_113\n",
      "75 conv2d_115\n",
      "76 conv2d_118\n",
      "77 conv2d_119\n",
      "78 batch_normalization_113\n",
      "79 batch_normalization_115\n",
      "80 batch_normalization_118\n",
      "81 batch_normalization_119\n",
      "82 activation_113\n",
      "83 activation_115\n",
      "84 activation_118\n",
      "85 activation_119\n",
      "86 mixed2\n",
      "87 conv2d_121\n",
      "88 batch_normalization_121\n",
      "89 activation_121\n",
      "90 conv2d_122\n",
      "91 batch_normalization_122\n",
      "92 activation_122\n",
      "93 conv2d_120\n",
      "94 conv2d_123\n",
      "95 batch_normalization_120\n",
      "96 batch_normalization_123\n",
      "97 activation_120\n",
      "98 activation_123\n",
      "99 max_pooling2d_6\n",
      "100 mixed3\n",
      "101 conv2d_128\n",
      "102 batch_normalization_128\n",
      "103 activation_128\n",
      "104 conv2d_129\n",
      "105 batch_normalization_129\n",
      "106 activation_129\n",
      "107 conv2d_125\n",
      "108 conv2d_130\n",
      "109 batch_normalization_125\n",
      "110 batch_normalization_130\n",
      "111 activation_125\n",
      "112 activation_130\n",
      "113 conv2d_126\n",
      "114 conv2d_131\n",
      "115 batch_normalization_126\n",
      "116 batch_normalization_131\n",
      "117 activation_126\n",
      "118 activation_131\n",
      "119 average_pooling2d_12\n",
      "120 conv2d_124\n",
      "121 conv2d_127\n",
      "122 conv2d_132\n",
      "123 conv2d_133\n",
      "124 batch_normalization_124\n",
      "125 batch_normalization_127\n",
      "126 batch_normalization_132\n",
      "127 batch_normalization_133\n",
      "128 activation_124\n",
      "129 activation_127\n",
      "130 activation_132\n",
      "131 activation_133\n",
      "132 mixed4\n",
      "133 conv2d_138\n",
      "134 batch_normalization_138\n",
      "135 activation_138\n",
      "136 conv2d_139\n",
      "137 batch_normalization_139\n",
      "138 activation_139\n",
      "139 conv2d_135\n",
      "140 conv2d_140\n",
      "141 batch_normalization_135\n",
      "142 batch_normalization_140\n",
      "143 activation_135\n",
      "144 activation_140\n",
      "145 conv2d_136\n",
      "146 conv2d_141\n",
      "147 batch_normalization_136\n",
      "148 batch_normalization_141\n",
      "149 activation_136\n",
      "150 activation_141\n",
      "151 average_pooling2d_13\n",
      "152 conv2d_134\n",
      "153 conv2d_137\n",
      "154 conv2d_142\n",
      "155 conv2d_143\n",
      "156 batch_normalization_134\n",
      "157 batch_normalization_137\n",
      "158 batch_normalization_142\n",
      "159 batch_normalization_143\n",
      "160 activation_134\n",
      "161 activation_137\n",
      "162 activation_142\n",
      "163 activation_143\n",
      "164 mixed5\n",
      "165 conv2d_148\n",
      "166 batch_normalization_148\n",
      "167 activation_148\n",
      "168 conv2d_149\n",
      "169 batch_normalization_149\n",
      "170 activation_149\n",
      "171 conv2d_145\n",
      "172 conv2d_150\n",
      "173 batch_normalization_145\n",
      "174 batch_normalization_150\n",
      "175 activation_145\n",
      "176 activation_150\n",
      "177 conv2d_146\n",
      "178 conv2d_151\n",
      "179 batch_normalization_146\n",
      "180 batch_normalization_151\n",
      "181 activation_146\n",
      "182 activation_151\n",
      "183 average_pooling2d_14\n",
      "184 conv2d_144\n",
      "185 conv2d_147\n",
      "186 conv2d_152\n",
      "187 conv2d_153\n",
      "188 batch_normalization_144\n",
      "189 batch_normalization_147\n",
      "190 batch_normalization_152\n",
      "191 batch_normalization_153\n",
      "192 activation_144\n",
      "193 activation_147\n",
      "194 activation_152\n",
      "195 activation_153\n",
      "196 mixed6\n",
      "197 conv2d_158\n",
      "198 batch_normalization_158\n",
      "199 activation_158\n",
      "200 conv2d_159\n",
      "201 batch_normalization_159\n",
      "202 activation_159\n",
      "203 conv2d_155\n",
      "204 conv2d_160\n",
      "205 batch_normalization_155\n",
      "206 batch_normalization_160\n",
      "207 activation_155\n",
      "208 activation_160\n",
      "209 conv2d_156\n",
      "210 conv2d_161\n",
      "211 batch_normalization_156\n",
      "212 batch_normalization_161\n",
      "213 activation_156\n",
      "214 activation_161\n",
      "215 average_pooling2d_15\n",
      "216 conv2d_154\n",
      "217 conv2d_157\n",
      "218 conv2d_162\n",
      "219 conv2d_163\n",
      "220 batch_normalization_154\n",
      "221 batch_normalization_157\n",
      "222 batch_normalization_162\n",
      "223 batch_normalization_163\n",
      "224 activation_154\n",
      "225 activation_157\n",
      "226 activation_162\n",
      "227 activation_163\n",
      "228 mixed7\n",
      "229 conv2d_166\n",
      "230 batch_normalization_166\n",
      "231 activation_166\n",
      "232 conv2d_167\n",
      "233 batch_normalization_167\n",
      "234 activation_167\n",
      "235 conv2d_164\n",
      "236 conv2d_168\n",
      "237 batch_normalization_164\n",
      "238 batch_normalization_168\n",
      "239 activation_164\n",
      "240 activation_168\n",
      "241 conv2d_165\n",
      "242 conv2d_169\n",
      "243 batch_normalization_165\n",
      "244 batch_normalization_169\n",
      "245 activation_165\n",
      "246 activation_169\n",
      "247 max_pooling2d_7\n",
      "248 mixed8\n",
      "249 conv2d_174\n",
      "250 batch_normalization_174\n",
      "251 activation_174\n",
      "252 conv2d_171\n",
      "253 conv2d_175\n",
      "254 batch_normalization_171\n",
      "255 batch_normalization_175\n",
      "256 activation_171\n",
      "257 activation_175\n",
      "258 conv2d_172\n",
      "259 conv2d_173\n",
      "260 conv2d_176\n",
      "261 conv2d_177\n",
      "262 average_pooling2d_16\n",
      "263 conv2d_170\n",
      "264 batch_normalization_172\n",
      "265 batch_normalization_173\n",
      "266 batch_normalization_176\n",
      "267 batch_normalization_177\n",
      "268 conv2d_178\n",
      "269 batch_normalization_170\n",
      "270 activation_172\n",
      "271 activation_173\n",
      "272 activation_176\n",
      "273 activation_177\n",
      "274 batch_normalization_178\n",
      "275 activation_170\n",
      "276 mixed9_0\n",
      "277 concatenate_2\n",
      "278 activation_178\n",
      "279 mixed9\n",
      "280 conv2d_183\n",
      "281 batch_normalization_183\n",
      "282 activation_183\n",
      "283 conv2d_180\n",
      "284 conv2d_184\n",
      "285 batch_normalization_180\n",
      "286 batch_normalization_184\n",
      "287 activation_180\n",
      "288 activation_184\n",
      "289 conv2d_181\n",
      "290 conv2d_182\n",
      "291 conv2d_185\n",
      "292 conv2d_186\n",
      "293 average_pooling2d_17\n",
      "294 conv2d_179\n",
      "295 batch_normalization_181\n",
      "296 batch_normalization_182\n",
      "297 batch_normalization_185\n",
      "298 batch_normalization_186\n",
      "299 conv2d_187\n",
      "300 batch_normalization_179\n",
      "301 activation_181\n",
      "302 activation_182\n",
      "303 activation_185\n",
      "304 activation_186\n",
      "305 batch_normalization_187\n",
      "306 activation_179\n",
      "307 mixed9_1\n",
      "308 concatenate_3\n",
      "309 activation_187\n",
      "310 mixed10\n",
      "311 global_average_pooling2d_1\n",
      "312 dense_layer\n",
      "313 output_fc\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 7/10000\n",
      "    882/Unknown - 522s 591ms/step - loss: 1.3040 - acc: 0.7045 - precision: 0.8736 - recall: 0.6196 - auc: 0.9672\n",
      "Epoch 00007: val_loss improved from inf to 1.27112, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000007-1.271116-1.303975.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - 614s 696ms/step - loss: 1.3040 - acc: 0.7045 - precision: 0.8736 - recall: 0.6196 - auc: 0.9672 - val_loss: 1.2711 - val_acc: 0.7277 - val_precision: 0.8323 - val_recall: 0.6834 - val_auc: 0.9612\n",
      "Epoch 8/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.6958 - acc: 0.8317 - precision: 0.9270 - recall: 0.7767 - auc: 0.9859\n",
      "Epoch 00008: val_loss improved from 1.27112 to 1.21233, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000008-1.212332-0.695958.hdf5\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.6960 - acc: 0.8316 - precision: 0.9270 - recall: 0.7767 - auc: 0.9859 - val_loss: 1.2123 - val_acc: 0.7203 - val_precision: 0.8442 - val_recall: 0.6631 - val_auc: 0.9668\n",
      "Epoch 9/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.8662 - precision: 0.9377 - recall: 0.8215 - auc: 0.9904\n",
      "Epoch 00009: val_loss improved from 1.21233 to 1.00575, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000009-1.005750-0.533541.hdf5\n",
      "882/882 [==============================] - 608s 689ms/step - loss: 0.5335 - acc: 0.8662 - precision: 0.9377 - recall: 0.8215 - auc: 0.9904 - val_loss: 1.0057 - val_acc: 0.7712 - val_precision: 0.8661 - val_recall: 0.7307 - val_auc: 0.9716\n",
      "Epoch 10/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8894 - precision: 0.9482 - recall: 0.8514 - auc: 0.9929\n",
      "Epoch 00010: val_loss improved from 1.00575 to 0.89947, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000010-0.899472-0.435386.hdf5\n",
      "882/882 [==============================] - 610s 691ms/step - loss: 0.4354 - acc: 0.8894 - precision: 0.9482 - recall: 0.8514 - auc: 0.9929 - val_loss: 0.8995 - val_acc: 0.8036 - val_precision: 0.8772 - val_recall: 0.7746 - val_auc: 0.9730\n",
      "Epoch 11/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.9091 - precision: 0.9546 - recall: 0.8791 - auc: 0.9947\n",
      "Epoch 00011: val_loss improved from 0.89947 to 0.78684, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000011-0.786842-0.353021.hdf5\n",
      "882/882 [==============================] - 609s 690ms/step - loss: 0.3530 - acc: 0.9090 - precision: 0.9546 - recall: 0.8791 - auc: 0.9947 - val_loss: 0.7868 - val_acc: 0.8263 - val_precision: 0.8895 - val_recall: 0.7996 - val_auc: 0.9766\n",
      "Epoch 12/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.9175 - precision: 0.9560 - recall: 0.8901 - auc: 0.9954\n",
      "Epoch 00012: val_loss did not improve from 0.78684\n",
      "882/882 [==============================] - 609s 690ms/step - loss: 0.3134 - acc: 0.9175 - precision: 0.9559 - recall: 0.8901 - auc: 0.9954 - val_loss: 0.9722 - val_acc: 0.7960 - val_precision: 0.8591 - val_recall: 0.7693 - val_auc: 0.9691\n",
      "Epoch 13/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9340 - precision: 0.9631 - recall: 0.9135 - auc: 0.9960\n",
      "Epoch 00013: val_loss did not improve from 0.78684\n",
      "882/882 [==============================] - 610s 692ms/step - loss: 0.2532 - acc: 0.9340 - precision: 0.9631 - recall: 0.9135 - auc: 0.9960 - val_loss: 0.9414 - val_acc: 0.8064 - val_precision: 0.8657 - val_recall: 0.7867 - val_auc: 0.9694\n",
      "Epoch 14/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9410 - precision: 0.9661 - recall: 0.9232 - auc: 0.9963\n",
      "Epoch 00014: val_loss did not improve from 0.78684\n",
      "882/882 [==============================] - 610s 691ms/step - loss: 0.2292 - acc: 0.9410 - precision: 0.9661 - recall: 0.9232 - auc: 0.9963 - val_loss: 0.8255 - val_acc: 0.8267 - val_precision: 0.8776 - val_recall: 0.8072 - val_auc: 0.9743\n",
      "Epoch 15/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9447 - precision: 0.9675 - recall: 0.9272 - auc: 0.9967\n",
      "Epoch 00015: val_loss did not improve from 0.78684\n",
      "882/882 [==============================] - 610s 691ms/step - loss: 0.2156 - acc: 0.9447 - precision: 0.9675 - recall: 0.9272 - auc: 0.9967 - val_loss: 0.9305 - val_acc: 0.8120 - val_precision: 0.8674 - val_recall: 0.7915 - val_auc: 0.9695\n",
      "Epoch 16/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9494 - precision: 0.9684 - recall: 0.9362 - auc: 0.9972\n",
      "Epoch 00016: val_loss improved from 0.78684 to 0.68641, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000016-0.686407-0.188841.hdf5\n",
      "882/882 [==============================] - 609s 690ms/step - loss: 0.1888 - acc: 0.9494 - precision: 0.9684 - recall: 0.9362 - auc: 0.9972 - val_loss: 0.6864 - val_acc: 0.8496 - val_precision: 0.9014 - val_recall: 0.8299 - val_auc: 0.9790\n",
      "Epoch 17/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9515 - precision: 0.9695 - recall: 0.9398 - auc: 0.9971\n",
      "Epoch 00017: val_loss did not improve from 0.68641\n",
      "882/882 [==============================] - 609s 691ms/step - loss: 0.1839 - acc: 0.9515 - precision: 0.9695 - recall: 0.9397 - auc: 0.9971 - val_loss: 0.7665 - val_acc: 0.8480 - val_precision: 0.8940 - val_recall: 0.8333 - val_auc: 0.9745\n",
      "Epoch 18/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9552 - precision: 0.9718 - recall: 0.9427 - auc: 0.9974\n",
      "Epoch 00018: val_loss did not improve from 0.68641\n",
      "882/882 [==============================] - 608s 690ms/step - loss: 0.1697 - acc: 0.9552 - precision: 0.9718 - recall: 0.9427 - auc: 0.9974 - val_loss: 0.6915 - val_acc: 0.8542 - val_precision: 0.8999 - val_recall: 0.8381 - val_auc: 0.9787\n",
      "Epoch 19/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9615 - precision: 0.9752 - recall: 0.9520 - auc: 0.9977\n",
      "Epoch 00019: val_loss did not improve from 0.68641\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.1468 - acc: 0.9615 - precision: 0.9752 - recall: 0.9520 - auc: 0.9977 - val_loss: 0.6967 - val_acc: 0.8509 - val_precision: 0.8951 - val_recall: 0.8334 - val_auc: 0.9788\n",
      "Epoch 20/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9608 - precision: 0.9736 - recall: 0.9511 - auc: 0.9977\n",
      "Epoch 00020: val_loss improved from 0.68641 to 0.67530, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000020-0.675297-0.147990.hdf5\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.1480 - acc: 0.9608 - precision: 0.9736 - recall: 0.9511 - auc: 0.9976 - val_loss: 0.6753 - val_acc: 0.8569 - val_precision: 0.9019 - val_recall: 0.8415 - val_auc: 0.9788\n",
      "Epoch 21/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9626 - precision: 0.9752 - recall: 0.9544 - auc: 0.9978\n",
      "Epoch 00021: val_loss improved from 0.67530 to 0.61806, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000021-0.618056-0.141631.hdf5\n",
      "882/882 [==============================] - 612s 693ms/step - loss: 0.1416 - acc: 0.9626 - precision: 0.9751 - recall: 0.9543 - auc: 0.9978 - val_loss: 0.6181 - val_acc: 0.8741 - val_precision: 0.9091 - val_recall: 0.8626 - val_auc: 0.9792\n",
      "Epoch 22/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9643 - precision: 0.9756 - recall: 0.9569 - auc: 0.9977\n",
      "Epoch 00022: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.1345 - acc: 0.9643 - precision: 0.9756 - recall: 0.9569 - auc: 0.9977 - val_loss: 0.7205 - val_acc: 0.8563 - val_precision: 0.8969 - val_recall: 0.8422 - val_auc: 0.9768\n",
      "Epoch 23/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9673 - precision: 0.9776 - recall: 0.9602 - auc: 0.9980\n",
      "Epoch 00023: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 612s 693ms/step - loss: 0.1240 - acc: 0.9673 - precision: 0.9776 - recall: 0.9602 - auc: 0.9980 - val_loss: 0.6366 - val_acc: 0.8749 - val_precision: 0.9097 - val_recall: 0.8646 - val_auc: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9675 - precision: 0.9774 - recall: 0.9607 - auc: 0.9981\n",
      "Epoch 00024: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 610s 692ms/step - loss: 0.1194 - acc: 0.9675 - precision: 0.9773 - recall: 0.9607 - auc: 0.9981 - val_loss: 0.6592 - val_acc: 0.8675 - val_precision: 0.9035 - val_recall: 0.8536 - val_auc: 0.9786\n",
      "Epoch 25/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9694 - precision: 0.9797 - recall: 0.9612 - auc: 0.9985\n",
      "Epoch 00025: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.1139 - acc: 0.9693 - precision: 0.9797 - recall: 0.9612 - auc: 0.9985 - val_loss: 0.6694 - val_acc: 0.8678 - val_precision: 0.8997 - val_recall: 0.8556 - val_auc: 0.9778\n",
      "Epoch 26/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9700 - precision: 0.9791 - recall: 0.9642 - auc: 0.9981\n",
      "Epoch 00026: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 610s 692ms/step - loss: 0.1125 - acc: 0.9700 - precision: 0.9791 - recall: 0.9642 - auc: 0.9981 - val_loss: 0.6485 - val_acc: 0.8778 - val_precision: 0.9071 - val_recall: 0.8680 - val_auc: 0.9778\n",
      "Epoch 27/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9757 - precision: 0.9829 - recall: 0.9706 - auc: 0.9985\n",
      "Epoch 00027: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 609s 691ms/step - loss: 0.0944 - acc: 0.9756 - precision: 0.9829 - recall: 0.9706 - auc: 0.9985 - val_loss: 0.6370 - val_acc: 0.8802 - val_precision: 0.9107 - val_recall: 0.8693 - val_auc: 0.9782\n",
      "Epoch 28/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9728 - precision: 0.9806 - recall: 0.9672 - auc: 0.9983\n",
      "Epoch 00028: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.1030 - acc: 0.9728 - precision: 0.9806 - recall: 0.9671 - auc: 0.9983 - val_loss: 0.6731 - val_acc: 0.8711 - val_precision: 0.9017 - val_recall: 0.8620 - val_auc: 0.9782\n",
      "Epoch 29/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9765 - precision: 0.9824 - recall: 0.9725 - auc: 0.9985\n",
      "Epoch 00029: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.0887 - acc: 0.9765 - precision: 0.9824 - recall: 0.9725 - auc: 0.9985 - val_loss: 0.6439 - val_acc: 0.8778 - val_precision: 0.9077 - val_recall: 0.8675 - val_auc: 0.9777\n",
      "Epoch 30/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9745 - precision: 0.9814 - recall: 0.9689 - auc: 0.9987\n",
      "Epoch 00030: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 610s 691ms/step - loss: 0.0955 - acc: 0.9745 - precision: 0.9814 - recall: 0.9689 - auc: 0.9987 - val_loss: 0.6269 - val_acc: 0.8818 - val_precision: 0.9091 - val_recall: 0.8727 - val_auc: 0.9792\n",
      "Epoch 31/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9765 - precision: 0.9828 - recall: 0.9719 - auc: 0.9987\n",
      "Epoch 00031: val_loss did not improve from 0.61806\n",
      "882/882 [==============================] - 609s 691ms/step - loss: 0.0877 - acc: 0.9765 - precision: 0.9828 - recall: 0.9719 - auc: 0.9987 - val_loss: 0.6209 - val_acc: 0.8824 - val_precision: 0.9104 - val_recall: 0.8702 - val_auc: 0.9789\n",
      "Epoch 32/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9785 - precision: 0.9846 - recall: 0.9742 - auc: 0.9987\n",
      "Epoch 00032: val_loss improved from 0.61806 to 0.60451, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000032-0.604505-0.080565.hdf5\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.0806 - acc: 0.9784 - precision: 0.9846 - recall: 0.9742 - auc: 0.9987 - val_loss: 0.6045 - val_acc: 0.8863 - val_precision: 0.9157 - val_recall: 0.8774 - val_auc: 0.9787\n",
      "Epoch 33/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9755 - precision: 0.9827 - recall: 0.9709 - auc: 0.9985\n",
      "Epoch 00033: val_loss did not improve from 0.60451\n",
      "882/882 [==============================] - 608s 690ms/step - loss: 0.0913 - acc: 0.9755 - precision: 0.9827 - recall: 0.9709 - auc: 0.9985 - val_loss: 0.6115 - val_acc: 0.8860 - val_precision: 0.9147 - val_recall: 0.8760 - val_auc: 0.9792\n",
      "Epoch 34/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9781 - precision: 0.9838 - recall: 0.9738 - auc: 0.9988\n",
      "Epoch 00034: val_loss did not improve from 0.60451\n",
      "882/882 [==============================] - 609s 691ms/step - loss: 0.0808 - acc: 0.9781 - precision: 0.9837 - recall: 0.9738 - auc: 0.9988 - val_loss: 0.6310 - val_acc: 0.8846 - val_precision: 0.9097 - val_recall: 0.8769 - val_auc: 0.9783\n",
      "Epoch 35/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9785 - precision: 0.9840 - recall: 0.9749 - auc: 0.9988\n",
      "Epoch 00035: val_loss did not improve from 0.60451\n",
      "882/882 [==============================] - 609s 691ms/step - loss: 0.0769 - acc: 0.9785 - precision: 0.9839 - recall: 0.9749 - auc: 0.9988 - val_loss: 0.7191 - val_acc: 0.8708 - val_precision: 0.8980 - val_recall: 0.8620 - val_auc: 0.9750\n",
      "Epoch 36/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9802 - precision: 0.9849 - recall: 0.9766 - auc: 0.9988\n",
      "Epoch 00036: val_loss improved from 0.60451 to 0.58235, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000036-0.582348-0.074912.hdf5\n",
      "882/882 [==============================] - 611s 692ms/step - loss: 0.0749 - acc: 0.9802 - precision: 0.9849 - recall: 0.9766 - auc: 0.9988 - val_loss: 0.5823 - val_acc: 0.8939 - val_precision: 0.9181 - val_recall: 0.8865 - val_auc: 0.9803\n",
      "Epoch 37/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9804 - precision: 0.9856 - recall: 0.9771 - auc: 0.9989\n",
      "Epoch 00037: val_loss did not improve from 0.58235\n",
      "882/882 [==============================] - 613s 695ms/step - loss: 0.0715 - acc: 0.9804 - precision: 0.9856 - recall: 0.9771 - auc: 0.9989 - val_loss: 0.6022 - val_acc: 0.8879 - val_precision: 0.9160 - val_recall: 0.8795 - val_auc: 0.9797\n",
      "Epoch 38/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9814 - precision: 0.9859 - recall: 0.9781 - auc: 0.9989\n",
      "Epoch 00038: val_loss did not improve from 0.58235\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0668 - acc: 0.9814 - precision: 0.9859 - recall: 0.9781 - auc: 0.9989 - val_loss: 0.5861 - val_acc: 0.8919 - val_precision: 0.9178 - val_recall: 0.8837 - val_auc: 0.9802\n",
      "Epoch 39/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9821 - precision: 0.9864 - recall: 0.9789 - auc: 0.9991\n",
      "Epoch 00039: val_loss did not improve from 0.58235\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0645 - acc: 0.9821 - precision: 0.9864 - recall: 0.9789 - auc: 0.9991 - val_loss: 0.6667 - val_acc: 0.8769 - val_precision: 0.9048 - val_recall: 0.8676 - val_auc: 0.9776\n",
      "Epoch 40/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9806 - precision: 0.9849 - recall: 0.9773 - auc: 0.9990\n",
      "Epoch 00040: val_loss did not improve from 0.58235\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0704 - acc: 0.9806 - precision: 0.9849 - recall: 0.9773 - auc: 0.9990 - val_loss: 0.6160 - val_acc: 0.8900 - val_precision: 0.9138 - val_recall: 0.8828 - val_auc: 0.9794\n",
      "Epoch 41/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9835 - precision: 0.9876 - recall: 0.9809 - auc: 0.9990\n",
      "Epoch 00041: val_loss did not improve from 0.58235\n",
      "882/882 [==============================] - 614s 696ms/step - loss: 0.0594 - acc: 0.9835 - precision: 0.9876 - recall: 0.9809 - auc: 0.9990 - val_loss: 0.6592 - val_acc: 0.8816 - val_precision: 0.9080 - val_recall: 0.8728 - val_auc: 0.9773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9796 - precision: 0.9845 - recall: 0.9764 - auc: 0.9989\n",
      "Epoch 00042: val_loss improved from 0.58235 to 0.56612, saving model to data/public/checkpoint/InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/000042-0.566119-0.071912.hdf5\n",
      "882/882 [==============================] - 613s 695ms/step - loss: 0.0719 - acc: 0.9796 - precision: 0.9844 - recall: 0.9764 - auc: 0.9989 - val_loss: 0.5661 - val_acc: 0.8997 - val_precision: 0.9244 - val_recall: 0.8925 - val_auc: 0.9804\n",
      "Epoch 43/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9853 - precision: 0.9890 - recall: 0.9829 - auc: 0.9992\n",
      "Epoch 00043: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0522 - acc: 0.9853 - precision: 0.9890 - recall: 0.9829 - auc: 0.9992 - val_loss: 0.6495 - val_acc: 0.8879 - val_precision: 0.9102 - val_recall: 0.8798 - val_auc: 0.9776\n",
      "Epoch 44/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9820 - precision: 0.9861 - recall: 0.9792 - auc: 0.9989\n",
      "Epoch 00044: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.0674 - acc: 0.9820 - precision: 0.9861 - recall: 0.9792 - auc: 0.9989 - val_loss: 0.5722 - val_acc: 0.8975 - val_precision: 0.9185 - val_recall: 0.8913 - val_auc: 0.9803\n",
      "Epoch 45/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9834 - precision: 0.9872 - recall: 0.9810 - auc: 0.9989\n",
      "Epoch 00045: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 613s 695ms/step - loss: 0.0611 - acc: 0.9833 - precision: 0.9871 - recall: 0.9809 - auc: 0.9988 - val_loss: 0.5803 - val_acc: 0.8969 - val_precision: 0.9183 - val_recall: 0.8886 - val_auc: 0.9802\n",
      "Epoch 46/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9858 - precision: 0.9891 - recall: 0.9836 - auc: 0.9992\n",
      "Epoch 00046: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0509 - acc: 0.9858 - precision: 0.9891 - recall: 0.9836 - auc: 0.9992 - val_loss: 0.6330 - val_acc: 0.8898 - val_precision: 0.9138 - val_recall: 0.8821 - val_auc: 0.9786\n",
      "Epoch 47/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9854 - precision: 0.9888 - recall: 0.9832 - auc: 0.9991\n",
      "Epoch 00047: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 693ms/step - loss: 0.0545 - acc: 0.9854 - precision: 0.9888 - recall: 0.9832 - auc: 0.9991 - val_loss: 0.5954 - val_acc: 0.8950 - val_precision: 0.9174 - val_recall: 0.8876 - val_auc: 0.9798\n",
      "Epoch 48/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9852 - precision: 0.9884 - recall: 0.9829 - auc: 0.9992\n",
      "Epoch 00048: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 613s 695ms/step - loss: 0.0534 - acc: 0.9852 - precision: 0.9884 - recall: 0.9829 - auc: 0.9992 - val_loss: 0.6225 - val_acc: 0.8952 - val_precision: 0.9161 - val_recall: 0.8891 - val_auc: 0.9778\n",
      "Epoch 49/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9840 - precision: 0.9876 - recall: 0.9818 - auc: 0.9991\n",
      "Epoch 00049: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0570 - acc: 0.9840 - precision: 0.9876 - recall: 0.9818 - auc: 0.9991 - val_loss: 0.6048 - val_acc: 0.8956 - val_precision: 0.9185 - val_recall: 0.8896 - val_auc: 0.9790\n",
      "Epoch 50/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9846 - precision: 0.9876 - recall: 0.9826 - auc: 0.9989\n",
      "Epoch 00050: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 693ms/step - loss: 0.0572 - acc: 0.9846 - precision: 0.9876 - recall: 0.9826 - auc: 0.9989 - val_loss: 0.6104 - val_acc: 0.8934 - val_precision: 0.9154 - val_recall: 0.8869 - val_auc: 0.9790\n",
      "Epoch 51/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9858 - precision: 0.9890 - recall: 0.9835 - auc: 0.9992\n",
      "Epoch 00051: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0515 - acc: 0.9858 - precision: 0.9890 - recall: 0.9835 - auc: 0.9991 - val_loss: 0.5814 - val_acc: 0.8971 - val_precision: 0.9191 - val_recall: 0.8909 - val_auc: 0.9800\n",
      "Epoch 52/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9864 - precision: 0.9893 - recall: 0.9843 - auc: 0.9991\n",
      "Epoch 00052: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 613s 695ms/step - loss: 0.0497 - acc: 0.9863 - precision: 0.9893 - recall: 0.9843 - auc: 0.9991 - val_loss: 0.6269 - val_acc: 0.8933 - val_precision: 0.9149 - val_recall: 0.8864 - val_auc: 0.9783\n",
      "Epoch 53/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9862 - precision: 0.9890 - recall: 0.9844 - auc: 0.9990\n",
      "Epoch 00053: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0520 - acc: 0.9862 - precision: 0.9890 - recall: 0.9844 - auc: 0.9990 - val_loss: 0.6606 - val_acc: 0.8920 - val_precision: 0.9136 - val_recall: 0.8863 - val_auc: 0.9769\n",
      "Epoch 54/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9857 - precision: 0.9885 - recall: 0.9838 - auc: 0.9992\n",
      "Epoch 00054: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0513 - acc: 0.9857 - precision: 0.9885 - recall: 0.9838 - auc: 0.9991 - val_loss: 0.5918 - val_acc: 0.8982 - val_precision: 0.9184 - val_recall: 0.8917 - val_auc: 0.9804\n",
      "Epoch 55/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9883 - precision: 0.9906 - recall: 0.9868 - auc: 0.9993\n",
      "Epoch 00055: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 612s 694ms/step - loss: 0.0443 - acc: 0.9883 - precision: 0.9906 - recall: 0.9868 - auc: 0.9993 - val_loss: 0.5888 - val_acc: 0.9029 - val_precision: 0.9216 - val_recall: 0.8965 - val_auc: 0.9796\n",
      "Epoch 56/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9871 - precision: 0.9901 - recall: 0.9848 - auc: 0.9994\n",
      "Epoch 00056: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 611s 692ms/step - loss: 0.0462 - acc: 0.9871 - precision: 0.9901 - recall: 0.9847 - auc: 0.9994 - val_loss: 0.5710 - val_acc: 0.8995 - val_precision: 0.9198 - val_recall: 0.8943 - val_auc: 0.9802\n",
      "Epoch 57/10000\n",
      "881/882 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9878 - precision: 0.9906 - recall: 0.9862 - auc: 0.9994\n",
      "Epoch 00057: val_loss did not improve from 0.56612\n",
      "882/882 [==============================] - 611s 693ms/step - loss: 0.0423 - acc: 0.9878 - precision: 0.9906 - recall: 0.9862 - auc: 0.9994 - val_loss: 0.6078 - val_acc: 0.8985 - val_precision: 0.9178 - val_recall: 0.8923 - val_auc: 0.9792\n",
      "Epoch 58/10000\n",
      "185/882 [=====>........................] - ETA: 6:51 - loss: 0.0857 - acc: 0.9769 - precision: 0.9819 - recall: 0.9749 - auc: 0.9983"
     ]
    }
   ],
   "source": [
    "for conv_comb, activation, base_channel, \\\n",
    "    between_type, fc_num, batch_size \\\n",
    "        in itertools.product(conv_comb_list, activation_list,\n",
    "                              base_channel_list, between_type_list, fc_list,\n",
    "                              batch_size_list):\n",
    "    config['conv']['conv_num'] = conv_comb\n",
    "    config['conv']['base_channel'] = base_channel\n",
    "    config['activation'] = activation\n",
    "    config['between_type'] = between_type\n",
    "    config['fc']['fc_num'] = fc_num\n",
    "    config['batch_size'] = batch_size\n",
    "\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # dataset = dataset.cache()\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(config['buffer_size'])\n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.TFRecordDataset(val_tfrecord_path, compression_type='GZIP')\n",
    "    val_dataset = val_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.shuffle(config['buffer_size'])\n",
    "    val_dataset = val_dataset.batch(config['batch_size'])\n",
    "    val_dataset = val_dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # val_dataset = val_dataset.cache()\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "\n",
    "    if pth.isdir(model_path) and len([_ for _ in os.listdir(model_path) if _.endswith('hdf5')]) >= 1:\n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "        initial_epoch = int(model_chk_name.split('-')[0])\n",
    "        model.load_weights(pth.join(model_path, model_chk_name))\n",
    "    else:\n",
    "        # first: train only the top layers (which were randomly initialized)\n",
    "        # i.e. freeze all convolutional InceptionV3 layers\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                     metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        PRE_TRAIN_EPOCH = 6\n",
    "        model.fit(\n",
    "            x=dataset, epochs=PRE_TRAIN_EPOCH, # train only top layers for just a few epochs.\n",
    "            validation_data=val_dataset, shuffle=True,\n",
    "            #callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "            initial_epoch=initial_epoch,\n",
    "            # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "            verbose=1)\n",
    "        \n",
    "        # at this point, the top layers are well trained and we can start fine-tuning\n",
    "        # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "        # and train the remaining top layers.\n",
    "        \n",
    "        # let's visualize layer names and layer indices to see how many layers\n",
    "        # we should freeze:\n",
    "        for i, layer in enumerate(model.layers):\n",
    "           print(i, layer.name)\n",
    "        \n",
    "        # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "        # the first 249 layers and unfreeze the rest:\n",
    "        for layer in model.layers[:229]:  # [:249]:\n",
    "           layer.trainable = False\n",
    "        for layer in model.layers[229:]:  # [249:]:\n",
    "           layer.trainable = True\n",
    "        \n",
    "        # we need to recompile the model for these modifications to take effect\n",
    "        # we use Adam with a low learning rate\n",
    "        model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "            metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "        initial_epoch = PRE_TRAIN_EPOCH\n",
    "\n",
    "        \n",
    "    # IGNORE 4 lines below in InceptionV3 \n",
    "    # ### Freeze first layer\n",
    "    # conv_list = [layer for layer in model.layers if isinstance(layer, keras.layers.Conv2D)]\n",
    "    # conv_list[0].trainable = False\n",
    "    # # conv_list[1].trainable = False\n",
    "\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = pth.join(model_path, '{epoch:06d}-{val_loss:0.6f}-{loss:0.6f}.hdf5')\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=model_filename, verbose=1, \n",
    "        period=1, save_best_only=True, \n",
    "        monitor='val_loss'\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=16)  ### 16 at night. 10 genral, 6 for experiment\n",
    "\n",
    "    hist = model.fit(\n",
    "        x=dataset, epochs=config['num_epoch'], \n",
    "        validation_data=val_dataset, shuffle=True,\n",
    "        callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "        initial_epoch=initial_epoch,\n",
    "        # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model_analysis_path = model_path.replace('checkpoint', 'analysis')\n",
    "    visualization_path = pth.join(model_analysis_path,'visualization')\n",
    "    os.makedirs(visualization_path, exist_ok=True)\n",
    "    \n",
    "    print()\n",
    "    # clear_output()        \n",
    "    for each_label in ['loss', 'acc', 'precision', 'recall', 'auc']:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(hist.history[each_label], 'g', label='train_{}'.format(each_label))\n",
    "        ax.plot(hist.history['val_{}'.format(each_label)], 'r', label='val_{}'.format(each_label))\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.legend(loc='upper left')\n",
    "        if not each_label == 'loss':\n",
    "            plt.ylim(0, 1)\n",
    "        plt.show()\n",
    "        filename = 'learning_curve_{}'.format(each_label)\n",
    "#             fig.savefig(pth.join(visualization_path, filename), transparent=True)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "\n",
    "    np.savez_compressed(pth.join(visualization_path, 'learning_curve'), \n",
    "                        loss=hist.history['loss'], \n",
    "                        val_loss=hist.history['val_loss'],\n",
    "                        acc=hist.history['acc'], \n",
    "                        val_acc=hist.history['val_acc'],\n",
    "                        precision=hist.history['precision'], \n",
    "                        vaval_precisionl_mae=hist.history['val_precision'],  \n",
    "                        recall=hist.history['recall'],\n",
    "                        val_recall=hist.history['val_recall'],\n",
    "                        auc=hist.history['auc'],\n",
    "                        val_auc=hist.history['val_auc']\n",
    "                        )\n",
    "\n",
    "    model.save(pth.join(model_path, '000000_last.hdf5'))\n",
    "    K.clear_session()\n",
    "    del(model)\n",
    "    \n",
    "    model_analysis_base_path = pth.join(model_base_path, 'analysis', model_name) \n",
    "    with open(pth.join(model_analysis_base_path, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "    chk_name_list = sorted([name for name in os.listdir(model_path) if name != '000000_last.hdf5'])\n",
    "    for chk_name in chk_name_list[:-2]:\n",
    "        os.remove(pth.join(model_path, chk_name))\n",
    "    # clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibXfENT5zvwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ARllmjWGk-"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "u1S7DrvwhFPM"
   },
   "outputs": [],
   "source": [
    "image_feature_description_for_test = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_for_test(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description_for_test)\n",
    "\n",
    "def map_func_for_test(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def resize_and_crop_func_for_test(image):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)\n",
    "    return result_image\n",
    "\n",
    "def post_process_func_for_test(image):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wi2igBp6WSYD"
   },
   "outputs": [],
   "source": [
    "submission_base_path = pth.join(data_base_path, 'submission')\n",
    "os.makedirs(submission_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "71z9_wKaMPTJ",
    "outputId": "aae36664-100b-46f1-ebd1-25a3804e4b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3-for-upload_resize_324_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "      2/Unknown - 0s 199ms/stepWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0310s vs `on_predict_batch_end` time: 0.3457s). Check your callbacks.\n",
      "475/475 [==============================] - 184s 388ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for conv_comb, activation, base_channel, \\\n",
    "    between_type, fc_num, batch_size \\\n",
    "        in itertools.product(conv_comb_list, activation_list,\n",
    "                              base_channel_list, between_type_list, fc_list,\n",
    "                              batch_size_list):\n",
    "    config['conv']['conv_num'] = conv_comb\n",
    "    config['conv']['base_channel'] = base_channel\n",
    "    config['activation'] = activation\n",
    "    config['between_type'] = between_type\n",
    "    config['fc']['fc_num'] = fc_num\n",
    "    config['batch_size'] = batch_size\n",
    "\n",
    "    base = BASE_MODEL_NAME\n",
    "\n",
    "    base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "\n",
    "    base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "    base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "    base += '_act_{}'.format(config['activation'])\n",
    "    base += '_pool_{}'.format(config['pool']['type'])\n",
    "    base += '_betw_{}'.format(config['between_type'])\n",
    "    base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "    base += '_zscore_{}'.format(config['is_zscore'])\n",
    "    base += '_batch_{}'.format(config['batch_size'])\n",
    "    if config['is_dropout']:\n",
    "        base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "    if config['is_batchnorm']:\n",
    "        base += '_BN'+'_O'\n",
    "    else:\n",
    "        base += '_BN'+'_X'\n",
    "\n",
    "    model_name = base\n",
    "    print(model_name)\n",
    "\n",
    "    ### Define dataset\n",
    "    test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(config['batch_size'])\n",
    "    test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model_path = pth.join(\n",
    "        model_checkpoint_path, model_name, \n",
    "    )\n",
    "    model = build_cnn(config)\n",
    "    #         model.summary()\n",
    "    model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "                  metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "    initial_epoch = 0\n",
    "\n",
    "    model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "    initial_epoch = int(model_chk_name.split('-')[0])\n",
    "    model.load_weights(pth.join(model_path, model_chk_name))\n",
    "\n",
    "    preds = model.predict(test_dataset, verbose=1)\n",
    "    \n",
    "    #pred_labels = np.argmax(preds, axis=1)\n",
    "    #pred_probs = np.array([pred[indice] for pred, indice in zip(preds, pred_labels)])\n",
    "    \n",
    "    # argmax --> top3\n",
    "    pred_labels = np.argsort(-preds)\n",
    "    \n",
    "    submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "    submission_df = pd.read_csv(submission_csv_path)\n",
    "    \n",
    "    merged_df = []\n",
    "    \n",
    "    RANK_TO_SAVE = 3\n",
    "    for i in range(RANK_TO_SAVE):\n",
    "        tmp_df = submission_df.copy()\n",
    "        \n",
    "        tmp_labels = pred_labels[:, i]\n",
    "        tmp_df['landmark_id'] = tmp_labels\n",
    "        tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])\n",
    "        merged_df.append(tmp_df)\n",
    "    \n",
    "    submission_df = pd.concat(merged_df)\n",
    "    \n",
    "    #submission_df['landmark_id'] = pred_labels\n",
    "    #submission_df['conf'] = pred_probs\n",
    "\n",
    "    today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "    result_filename = '{}.csv'.format(model_name)\n",
    "    submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "    submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMStwUj7nYz9"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Training_MobileNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
