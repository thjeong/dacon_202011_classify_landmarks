{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XDnap1jLv8so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import os.path as pth\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffY3gSLAvvSs"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = 'ResNet50V2-kfold'\n",
    "my_model_base = keras.applications.resnet_v2\n",
    "my_model = my_model_base.ResNet50V2\n",
    "\n",
    "config = {\n",
    "    'is_zscore':True,\n",
    "    \n",
    "    # 'input_shape': (540, 960, 3),\n",
    "    'aug': {\n",
    "        'resize': (270, 480),\n",
    "        #'resize': (297, 528),\n",
    "    },\n",
    "    # 'input_shape': (224, 360, 3),\n",
    "    #'input_shape': (270, 480, 3),\n",
    "    'input_shape': (270, 480, 3),\n",
    "\n",
    "    'output_activation': 'softmax',\n",
    "    'num_class': 1049,\n",
    "    'output_size': 1049,\n",
    "    \n",
    "    'conv':{\n",
    "        'conv_num': (0,), # (3,5,3),\n",
    "        'base_channel': 0, # 4,\n",
    "        'kernel_size': 0, # 3,\n",
    "        'padding':'same',\n",
    "        'stride':'X'\n",
    "    },\n",
    "    'pool':{\n",
    "        'type':'X',\n",
    "        'size':'X',\n",
    "        'stride':'X',\n",
    "        'padding':'same'\n",
    "    },\n",
    "    'fc':{\n",
    "        'fc_num': 0,\n",
    "     },\n",
    "    \n",
    "    'activation':'relu',\n",
    "    \n",
    "    'between_type': 'avg',\n",
    "    \n",
    "    'is_batchnorm': True,\n",
    "    'is_dropout': False,\n",
    "    'dropout_rate': 0.5,\n",
    "    \n",
    "    'batch_size': 80,\n",
    "    'buffer_size': 256,\n",
    "    'loss': 'CategoricalCrossentropy',\n",
    "    \n",
    "    #'num_epoch': 10000,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    'random_state': 7777\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BASE_MODEL_NAME\n",
    "\n",
    "base += '_resize_{}'.format(config['aug']['resize'][0])\n",
    "#base += '_input_{}'.format(config['input_shape'][0])\n",
    "base += '_conv_{}'.format('-'.join(map(lambda x:str(x),config['conv']['conv_num'])))\n",
    "base += '_basech_{}'.format(config['conv']['base_channel'])\n",
    "base += '_act_{}'.format(config['activation'])\n",
    "base += '_pool_{}'.format(config['pool']['type'])\n",
    "base += '_betw_{}'.format(config['between_type'])\n",
    "base += '_fc_{}'.format(config['fc']['fc_num'])\n",
    "base += '_zscore_{}'.format(config['is_zscore'])\n",
    "base += '_batch_{}'.format(config['batch_size'])\n",
    "if config['is_dropout']:\n",
    "    base += '_DO_'+str(config['dropout_rate']).replace('.', '')\n",
    "if config['is_batchnorm']:\n",
    "    base += '_BN'+'_O'\n",
    "else:\n",
    "    base += '_BN'+'_X'\n",
    "\n",
    "model_name = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "j1UN3LYJzFgd"
   },
   "outputs": [],
   "source": [
    "data_base_path = pth.join('data', 'public') \n",
    "os.makedirs(data_base_path, exist_ok=True)\n",
    "\n",
    "model_base_path = data_base_path\n",
    "model_checkpoint_path = pth.join(model_base_path, 'checkpoint')\n",
    "\n",
    "model_path = pth.join(model_checkpoint_path, model_name)\n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "FILENAMES = tf.io.gfile.glob(pth.join(data_base_path, 'train_tfrec', '*'))\n",
    "TEST_FILENAMES = tf.io.gfile.glob(pth.join(data_base_path, 'test_tfrec', '*'))\n",
    "\n",
    "# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\n",
    "SEED = 42\n",
    "\n",
    "# NUMBER OF FOLDS. USE 3, 5, OR 15 \n",
    "FOLDS = 5\n",
    "\n",
    "#BATCH_SIZES = [32]*FOLDS\n",
    "EPOCHS = [9]*FOLDS\n",
    "\n",
    "PRE_TRAIN_EPOCH = 1\n",
    "\n",
    "# WGTS - this should be 1/FOLDS for each fold. This is the weight when ensembling the folds to predict the test set. If you want a weird ensemble, you can use different weights.\n",
    "# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\n",
    "WGTS = [1/FOLDS]*FOLDS\n",
    "\n",
    "\n",
    "# TEST TIME AUGMENTATION STEPS\n",
    "TTA = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "abOw4s0jv6JI"
   },
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'landmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['landmark_id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def resize_and_crop_func(image, label):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    #result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # crop revived.\n",
    "    return result_image, label\n",
    "\n",
    "def image_aug_func(img, label):\n",
    "    #pass\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    #img = tf.image.random_hue(img, 0.01)\n",
    "    img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    img = tf.image.random_brightness(img, 0.1)\n",
    "    return img, label\n",
    "\n",
    "def post_process_func(image, label):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    onehot_label = tf.one_hot(label, depth=config['num_class'])\n",
    "    return result_image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ks1l_51cNzLP"
   },
   "outputs": [],
   "source": [
    "category_csv_name = 'category.csv'\n",
    "category_json_name = 'category.json'\n",
    "submission_csv_name = 'sample_submisstion.csv'\n",
    "train_csv_name = 'train.csv'\n",
    "\n",
    "# train_zip_name = 'train.zip'\n",
    "train_tfrecord_name = 'all_train.tfrecords'\n",
    "train_tfrecord_path = pth.join(data_base_path, train_tfrecord_name)\n",
    "val_tfrecord_name = 'all_val.tfrecords'\n",
    "val_tfrecord_path = pth.join(data_base_path, val_tfrecord_name)\n",
    "# test_zip_name = 'test.zip'\n",
    "test_tfrecord_name = 'test.tfrecords'\n",
    "test_tfrecord_path = pth.join(data_base_path, test_tfrecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MaBBHyX0dMig"
   },
   "outputs": [],
   "source": [
    "train_csv_path = pth.join(data_base_path, train_csv_name)\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_dict = {k:v for k, v in train_df.values}\n",
    "\n",
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "# submission_df.head()\n",
    "\n",
    "category_csv_path = pth.join(data_base_path, category_csv_name)\n",
    "category_df = pd.read_csv(category_csv_path)\n",
    "category_dict = {k:v for k, v in category_df.values}\n",
    "# category_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdng6pk8k0fH"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Q9-4T5OMcy1R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, GroupKFold, RepeatedStratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as pth\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import datetime\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv3D, AveragePooling3D, MaxPooling3D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool3D, GlobalAvgPool3D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAaKPD3cnKB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WrRPrv1aoOEA"
   },
   "outputs": [],
   "source": [
    "def build_cnn(config):\n",
    "    input_layer = Input(shape=config['input_shape'], name='input_layer')\n",
    "    pret_model = my_model(\n",
    "        input_tensor=input_layer, include_top=False, weights='imagenet', \n",
    "        input_shape=config['input_shape'], pooling=config['between_type'], \n",
    "        classes=config['output_size']\n",
    "    )\n",
    "\n",
    "    pret_model.trainable = False\n",
    "    \n",
    "    x = pret_model.output\n",
    "    \n",
    "    if config['between_type'] == None:\n",
    "        x = Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "    if config['is_dropout']:\n",
    "        x = Dropout(config['dropout_rate'], name='output_dropout')(x)    \n",
    "            \n",
    "    x = Dense(config['output_size'], activation=config['output_activation'], \n",
    "          name='output_fc')(x)\n",
    "#     x = Activation(activation=config['output_activation'], name='output_activation')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x, name='{}'.format(BASE_MODEL_NAME))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d5mZ06q3qAmN",
    "outputId": "edc1edc4-147a-43c3-e8c4-0ae69fa5e59d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50V2-kfold\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_layer (InputLayer)                         [(None, 270, 480, 3)]            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)                        (None, 276, 486, 3)              0                 input_layer[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)                              (None, 135, 240, 64)             9472              conv1_pad[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)                        (None, 137, 242, 64)             0                 conv1_conv[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)                        (None, 68, 120, 64)              0                 pool1_pad[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNormalization)      (None, 68, 120, 64)              256               pool1_pool[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activation)            (None, 68, 120, 64)              0                 conv2_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)                     (None, 68, 120, 64)              4096              conv2_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)                     (None, 68, 120, 64)              36864             conv2_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)                           (None, 68, 120, 256)             0                 conv2_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv2_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNormalization)      (None, 68, 120, 256)             1024              conv2_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activation)            (None, 68, 120, 256)             0                 conv2_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)                     (None, 68, 120, 64)              16384             conv2_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)                     (None, 68, 120, 64)              36864             conv2_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)                     (None, 68, 120, 256)             16640             conv2_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)                           (None, 68, 120, 256)             0                 conv2_block1_out[0][0]                            \n",
      "                                                                                                    conv2_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNormalization)      (None, 68, 120, 256)             1024              conv2_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activation)            (None, 68, 120, 256)             0                 conv2_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)                     (None, 68, 120, 64)              16384             conv2_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormalization)           (None, 68, 120, 64)              256               conv2_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation)                 (None, 68, 120, 64)              0                 conv2_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding2D)               (None, 70, 122, 64)              0                 conv2_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)                     (None, 34, 60, 64)               36864             conv2_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormalization)           (None, 34, 60, 64)               256               conv2_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation)                 (None, 34, 60, 64)               0                 conv2_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)                   (None, 34, 60, 256)              0                 conv2_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)                     (None, 34, 60, 256)              16640             conv2_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)                           (None, 34, 60, 256)              0                 max_pooling2d_3[0][0]                             \n",
      "                                                                                                    conv2_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNormalization)      (None, 34, 60, 256)              1024              conv2_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activation)            (None, 34, 60, 256)              0                 conv3_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)                     (None, 34, 60, 128)              32768             conv3_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)                     (None, 34, 60, 512)              131584            conv3_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)                           (None, 34, 60, 512)              0                 conv3_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv3_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)                           (None, 34, 60, 512)              0                 conv3_block1_out[0][0]                            \n",
      "                                                                                                    conv3_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)                     (None, 34, 60, 128)              147456            conv3_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)                     (None, 34, 60, 512)              66048             conv3_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)                           (None, 34, 60, 512)              0                 conv3_block2_out[0][0]                            \n",
      "                                                                                                    conv3_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNormalization)      (None, 34, 60, 512)              2048              conv3_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activation)            (None, 34, 60, 512)              0                 conv3_block4_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)                     (None, 34, 60, 128)              65536             conv3_block4_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormalization)           (None, 34, 60, 128)              512               conv3_block4_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation)                 (None, 34, 60, 128)              0                 conv3_block4_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding2D)               (None, 36, 62, 128)              0                 conv3_block4_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)                     (None, 17, 30, 128)              147456            conv3_block4_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormalization)           (None, 17, 30, 128)              512               conv3_block4_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation)                 (None, 17, 30, 128)              0                 conv3_block4_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)                   (None, 17, 30, 512)              0                 conv3_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)                     (None, 17, 30, 512)              66048             conv3_block4_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)                           (None, 17, 30, 512)              0                 max_pooling2d_4[0][0]                             \n",
      "                                                                                                    conv3_block4_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNormalization)      (None, 17, 30, 512)              2048              conv3_block4_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activation)            (None, 17, 30, 512)              0                 conv4_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)                     (None, 17, 30, 256)              131072            conv4_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)                     (None, 17, 30, 1024)             525312            conv4_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv4_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block1_out[0][0]                            \n",
      "                                                                                                    conv4_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block2_out[0][0]                            \n",
      "                                                                                                    conv4_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block4_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block4_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block4_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block4_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block4_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block4_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block4_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block4_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block4_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block3_out[0][0]                            \n",
      "                                                                                                    conv4_block4_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block4_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block5_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block5_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block5_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block5_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block5_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)                     (None, 17, 30, 256)              589824            conv4_block5_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block5_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block5_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)                     (None, 17, 30, 1024)             263168            conv4_block5_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)                           (None, 17, 30, 1024)             0                 conv4_block4_out[0][0]                            \n",
      "                                                                                                    conv4_block5_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNormalization)      (None, 17, 30, 1024)             4096              conv4_block5_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activation)            (None, 17, 30, 1024)             0                 conv4_block6_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)                     (None, 17, 30, 256)              262144            conv4_block6_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormalization)           (None, 17, 30, 256)              1024              conv4_block6_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation)                 (None, 17, 30, 256)              0                 conv4_block6_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding2D)               (None, 19, 32, 256)              0                 conv4_block6_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)                     (None, 9, 15, 256)               589824            conv4_block6_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormalization)           (None, 9, 15, 256)               1024              conv4_block6_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation)                 (None, 9, 15, 256)               0                 conv4_block6_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)                   (None, 9, 15, 1024)              0                 conv4_block5_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)                     (None, 9, 15, 1024)              263168            conv4_block6_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)                           (None, 9, 15, 1024)              0                 max_pooling2d_5[0][0]                             \n",
      "                                                                                                    conv4_block6_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNormalization)      (None, 9, 15, 1024)              4096              conv4_block6_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activation)            (None, 9, 15, 1024)              0                 conv5_block1_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)                     (None, 9, 15, 512)               524288            conv5_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block1_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block1_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block1_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block1_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block1_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block1_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)                     (None, 9, 15, 2048)              2099200           conv5_block1_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block1_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block1_0_conv[0][0]                         \n",
      "                                                                                                    conv5_block1_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNormalization)      (None, 9, 15, 2048)              8192              conv5_block1_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activation)            (None, 9, 15, 2048)              0                 conv5_block2_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)                     (None, 9, 15, 512)               1048576           conv5_block2_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block2_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block2_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block2_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block2_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block2_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block2_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block2_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block1_out[0][0]                            \n",
      "                                                                                                    conv5_block2_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNormalization)      (None, 9, 15, 2048)              8192              conv5_block2_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activation)            (None, 9, 15, 2048)              0                 conv5_block3_preact_bn[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)                     (None, 9, 15, 512)               1048576           conv5_block3_preact_relu[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block3_1_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block3_1_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding2D)               (None, 11, 17, 512)              0                 conv5_block3_1_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)                     (None, 9, 15, 512)               2359296           conv5_block3_2_pad[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormalization)           (None, 9, 15, 512)               2048              conv5_block3_2_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation)                 (None, 9, 15, 512)               0                 conv5_block3_2_bn[0][0]                           \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)                     (None, 9, 15, 2048)              1050624           conv5_block3_2_relu[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)                           (None, 9, 15, 2048)              0                 conv5_block2_out[0][0]                            \n",
      "                                                                                                    conv5_block3_3_conv[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)                     (None, 9, 15, 2048)              8192              conv5_block3_out[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "post_relu (Activation)                           (None, 9, 15, 2048)              0                 post_bn[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D)                (None, 2048)                     0                 post_relu[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "output_fc (Dense)                                (None, 1049)                     2149401           avg_pool[0][0]                                    \n",
      "======================================================================================================================================================\n",
      "Total params: 25,714,201\n",
      "Trainable params: 2,149,401\n",
      "Non-trainable params: 23,564,800\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(config)\n",
    "model.summary(line_length=150)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCsZqqHyqAds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training tfrecords \n",
    "def read_tr_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"landmark_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     target = tf.cast(example['landmark_id'], tf.int64)\n",
    "#     return image, target\n",
    "\n",
    "# validation tfrecords \n",
    "def read_val_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"landmark_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     target = tf.cast(example['landmark_id'], tf.int64)\n",
    "#     return image, target\n",
    "\n",
    "# test tfrecords \n",
    "def read_test_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string), \n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "         }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    return example\n",
    "#     image = example['image_raw']\n",
    "#     id = example['id']\n",
    "#     return image, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(filenames, ordered = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(config['buffer_size'])\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_tr_tfrecord, num_parallel_calls = AUTO)\n",
    "    \n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset(filenames, ordered = True, prediction = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_val_tfrecord, num_parallel_calls = AUTO)\n",
    "    \n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #dataset = dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if prediction:\n",
    "        dataset = dataset.batch(config['batch_size'] * 4)  # why 4 times?\n",
    "    else:\n",
    "        dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description_for_test = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_for_test(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description_for_test)\n",
    "\n",
    "def map_func_for_test(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def resize_and_crop_func_for_test(image):\n",
    "    result_image = tf.image.resize(image, config['aug']['resize'])\n",
    "    #result_image = tf.image.random_crop(image, size=config['input_shape'], seed=7777)  # revive\n",
    "    return result_image\n",
    "\n",
    "\n",
    "def image_aug_func_for_test(img):\n",
    "    #pass\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    #img = tf.image.random_hue(img, 0.01)\n",
    "    img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    img = tf.image.random_brightness(img, 0.1)\n",
    "    return img\n",
    "\n",
    "def post_process_func_for_test(image):\n",
    "    # result_image = result_image / 255\n",
    "    result_image = my_model_base.preprocess_input(image)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_just_image(image, id):\n",
    "#     return image\n",
    "# def test_just_id(image, id):\n",
    "#     return id\n",
    "\n",
    "def get_test_dataset(filenames, ordered=True, prediction=False, name=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_test_tfrecord, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(image_aug_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "#     if name:\n",
    "#         dataset = dataset.map(test_just_id, num_parallel_calls = AUTO)\n",
    "#     else:\n",
    "#         dataset = dataset.map(test_just_image, num_parallel_calls = AUTO)\n",
    "    \n",
    "    dataset = dataset.batch(config['batch_size'])\n",
    "    dataset = dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 0.000001*10*0.5\n",
    "    lr_max     = 0.0000005 * config['batch_size'] * 10*0.5\n",
    "    lr_min     = 0.000001 * 10*0.5\n",
    "    #lr_ramp_ep = 3 #### TODO: NEED TO BE CONSIDERED WISELY.  # 5\n",
    "    lr_ramp_ep = 2 #### (small lr) going up -> ramp (large max lr) -> going down (small lr)\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "     \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max    \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "        print('lr=',lr)\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ta_kqsLstQcV",
    "outputId": "760909ad-2f6c-444c-aa85-43ab5e364c6b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### FOLD 3\n",
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "#########################\n",
      "882/882 [==============================] - 591s 670ms/step - loss: 1.9343 - acc: 0.6900 - precision: 0.9727 - recall: 0.4884 - auc: 0.9380 - val_loss: 0.7088 - val_acc: 0.8556 - val_precision: 0.9651 - val_recall: 0.7698 - val_auc: 0.9859\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "lr= 4.9999999999999996e-06\n",
      "Epoch 1/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.7882 - acc: 0.8544 - precision: 0.9802 - recall: 0.7250 - auc: 0.9877\n",
      "Epoch 00001: val_loss improved from inf to 0.62666, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000001-0.626661-0.788199.hdf5\n",
      "882/882 [==============================] - 667s 757ms/step - loss: 0.7882 - acc: 0.8544 - precision: 0.9802 - recall: 0.7250 - auc: 0.9877 - val_loss: 0.6267 - val_acc: 0.8782 - val_precision: 0.9816 - val_recall: 0.7844 - val_auc: 0.9897\n",
      "lr= 0.00010249999999999998\n",
      "Epoch 2/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.2553 - acc: 0.9487 - precision: 0.9892 - recall: 0.9088 - auc: 0.9973\n",
      "Epoch 00002: val_loss improved from 0.62666 to 0.24374, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000002-0.243739-0.255300.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.2553 - acc: 0.9487 - precision: 0.9892 - recall: 0.9088 - auc: 0.9973 - val_loss: 0.2437 - val_acc: 0.9467 - val_precision: 0.9828 - val_recall: 0.9203 - val_auc: 0.9959\n",
      "lr= 0.00019999999999999998\n",
      "Epoch 3/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0768 - acc: 0.9858 - precision: 0.9958 - recall: 0.9749 - auc: 0.9997\n",
      "Epoch 00003: val_loss improved from 0.24374 to 0.21761, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000003-0.217613-0.076846.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0768 - acc: 0.9858 - precision: 0.9958 - recall: 0.9749 - auc: 0.9997 - val_loss: 0.2176 - val_acc: 0.9501 - val_precision: 0.9754 - val_recall: 0.9341 - val_auc: 0.9954\n",
      "lr= 0.000161\n",
      "Epoch 4/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9982 - precision: 0.9989 - recall: 0.9966 - auc: 1.0000\n",
      "Epoch 00004: val_loss improved from 0.21761 to 0.17696, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000004-0.176956-0.016116.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 0.0161 - acc: 0.9982 - precision: 0.9989 - recall: 0.9966 - auc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9603 - val_precision: 0.9785 - val_recall: 0.9498 - val_auc: 0.9961\n",
      "lr= 0.0001298\n",
      "Epoch 5/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9996 - precision: 0.9997 - recall: 0.9993 - auc: 1.0000\n",
      "Epoch 00005: val_loss improved from 0.17696 to 0.16221, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000005-0.162208-0.005773.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0058 - acc: 0.9996 - precision: 0.9997 - recall: 0.9993 - auc: 1.0000 - val_loss: 0.1622 - val_acc: 0.9637 - val_precision: 0.9804 - val_recall: 0.9549 - val_auc: 0.9961\n",
      "lr= 0.00010484\n",
      "Epoch 6/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0029 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00006: val_loss improved from 0.16221 to 0.15496, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000006-0.154964-0.002898.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 0.0029 - acc: 0.9998 - precision: 0.9999 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9665 - val_precision: 0.9810 - val_recall: 0.9597 - val_auc: 0.9957\n",
      "lr= 8.4872e-05\n",
      "Epoch 7/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0017 - acc: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000\n",
      "Epoch 00007: val_loss improved from 0.15496 to 0.15485, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000007-0.154854-0.001749.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0017 - acc: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.1549 - val_acc: 0.9674 - val_precision: 0.9806 - val_recall: 0.9602 - val_auc: 0.9960\n",
      "lr= 6.88976e-05\n",
      "Epoch 8/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0013 - acc: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.15485 to 0.15313, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000008-0.153127-0.001274.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 0.0013 - acc: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.1531 - val_acc: 0.9673 - val_precision: 0.9803 - val_recall: 0.9612 - val_auc: 0.9959\n",
      "lr= 5.611808000000001e-05\n",
      "Epoch 9/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 9.2135e-04 - acc: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000\n",
      "Epoch 00009: val_loss did not improve from 0.15313\n",
      "882/882 [==============================] - 666s 756ms/step - loss: 9.2135e-04 - acc: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9653 - val_precision: 0.9784 - val_recall: 0.9596 - val_auc: 0.9952\n",
      "#########################\n",
      "#### FOLD 4\n",
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "#########################\n",
      "882/882 [==============================] - 589s 667ms/step - loss: 1.9199 - acc: 0.6910 - precision: 0.9740 - recall: 0.4910 - auc: 0.9394 - val_loss: 0.7307 - val_acc: 0.8493 - val_precision: 0.9642 - val_recall: 0.7647 - val_auc: 0.9849\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "lr= 4.9999999999999996e-06\n",
      "Epoch 1/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.7895 - acc: 0.8530 - precision: 0.9773 - recall: 0.7188 - auc: 0.9881\n",
      "Epoch 00001: val_loss improved from inf to 0.65163, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000001-0.651627-0.789469.hdf5\n",
      "882/882 [==============================] - 668s 757ms/step - loss: 0.7895 - acc: 0.8530 - precision: 0.9773 - recall: 0.7188 - auc: 0.9881 - val_loss: 0.6516 - val_acc: 0.8728 - val_precision: 0.9788 - val_recall: 0.7783 - val_auc: 0.9893\n",
      "lr= 0.00010249999999999998\n",
      "Epoch 2/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.2556 - acc: 0.9496 - precision: 0.9887 - recall: 0.9094 - auc: 0.9972\n",
      "Epoch 00002: val_loss improved from 0.65163 to 0.25303, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000002-0.253025-0.255587.hdf5\n",
      "882/882 [==============================] - 669s 758ms/step - loss: 0.2556 - acc: 0.9496 - precision: 0.9887 - recall: 0.9094 - auc: 0.9972 - val_loss: 0.2530 - val_acc: 0.9448 - val_precision: 0.9812 - val_recall: 0.9187 - val_auc: 0.9957\n",
      "lr= 0.00019999999999999998\n",
      "Epoch 3/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0763 - acc: 0.9868 - precision: 0.9958 - recall: 0.9750 - auc: 0.9996\n",
      "Epoch 00003: val_loss improved from 0.25303 to 0.22756, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000003-0.227561-0.076326.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - 668s 758ms/step - loss: 0.0763 - acc: 0.9868 - precision: 0.9958 - recall: 0.9750 - auc: 0.9996 - val_loss: 0.2276 - val_acc: 0.9476 - val_precision: 0.9767 - val_recall: 0.9288 - val_auc: 0.9958\n",
      "lr= 0.000161\n",
      "Epoch 4/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9982 - precision: 0.9990 - recall: 0.9968 - auc: 1.0000\n",
      "Epoch 00004: val_loss improved from 0.22756 to 0.17261, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000004-0.172609-0.016109.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0161 - acc: 0.9982 - precision: 0.9990 - recall: 0.9968 - auc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9611 - val_precision: 0.9800 - val_recall: 0.9505 - val_auc: 0.9958\n",
      "lr= 0.0001298\n",
      "Epoch 5/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9997 - precision: 0.9998 - recall: 0.9994 - auc: 1.0000\n",
      "Epoch 00005: val_loss improved from 0.17261 to 0.16291, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000005-0.162911-0.005513.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 0.0055 - acc: 0.9997 - precision: 0.9998 - recall: 0.9994 - auc: 1.0000 - val_loss: 0.1629 - val_acc: 0.9631 - val_precision: 0.9815 - val_recall: 0.9532 - val_auc: 0.9963\n",
      "lr= 0.00010484\n",
      "Epoch 6/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9996 - precision: 0.9997 - recall: 0.9995 - auc: 1.0000\n",
      "Epoch 00006: val_loss improved from 0.16291 to 0.16090, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000006-0.160900-0.003600.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0036 - acc: 0.9996 - precision: 0.9997 - recall: 0.9995 - auc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9638 - val_precision: 0.9808 - val_recall: 0.9547 - val_auc: 0.9964\n",
      "lr= 8.4872e-05\n",
      "Epoch 7/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00007: val_loss improved from 0.16090 to 0.15515, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000007-0.155153-0.002835.hdf5\n",
      "882/882 [==============================] - 666s 755ms/step - loss: 0.0028 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.1552 - val_acc: 0.9650 - val_precision: 0.9818 - val_recall: 0.9570 - val_auc: 0.9964\n",
      "lr= 6.88976e-05\n",
      "Epoch 8/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.15515 to 0.15230, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000008-0.152299-0.001266.hdf5\n",
      "882/882 [==============================] - 667s 756ms/step - loss: 0.0013 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1523 - val_acc: 0.9659 - val_precision: 0.9803 - val_recall: 0.9584 - val_auc: 0.9964\n",
      "lr= 5.611808000000001e-05\n",
      "Epoch 9/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 7.6852e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00009: val_loss improved from 0.15230 to 0.15036, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000009-0.150363-0.000769.hdf5\n",
      "882/882 [==============================] - 666s 756ms/step - loss: 7.6852e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9671 - val_precision: 0.9813 - val_recall: 0.9599 - val_auc: 0.9963\n",
      "#########################\n",
      "#### FOLD 5\n",
      "ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O\n",
      "#########################\n",
      "882/882 [==============================] - 592s 671ms/step - loss: 1.9164 - acc: 0.6928 - precision: 0.9724 - recall: 0.4908 - auc: 0.9395 - val_loss: 0.7131 - val_acc: 0.8566 - val_precision: 0.9668 - val_recall: 0.7728 - val_auc: 0.9853\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "lr= 4.9999999999999996e-06\n",
      "Epoch 1/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.7787 - acc: 0.8569 - precision: 0.9774 - recall: 0.7221 - auc: 0.9882\n",
      "Epoch 00001: val_loss improved from inf to 0.63646, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000001-0.636455-0.778742.hdf5\n",
      "882/882 [==============================] - 669s 758ms/step - loss: 0.7787 - acc: 0.8569 - precision: 0.9774 - recall: 0.7221 - auc: 0.9882 - val_loss: 0.6365 - val_acc: 0.8761 - val_precision: 0.9814 - val_recall: 0.7831 - val_auc: 0.9905\n",
      "lr= 0.00010249999999999998\n",
      "Epoch 2/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.2565 - acc: 0.9487 - precision: 0.9884 - recall: 0.9077 - auc: 0.9973\n",
      "Epoch 00002: val_loss improved from 0.63646 to 0.24191, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000002-0.241912-0.256495.hdf5\n",
      "882/882 [==============================] - 670s 760ms/step - loss: 0.2565 - acc: 0.9487 - precision: 0.9884 - recall: 0.9077 - auc: 0.9973 - val_loss: 0.2419 - val_acc: 0.9461 - val_precision: 0.9836 - val_recall: 0.9170 - val_auc: 0.9966\n",
      "lr= 0.00019999999999999998\n",
      "Epoch 3/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.9859 - precision: 0.9956 - recall: 0.9740 - auc: 0.9996\n",
      "Epoch 00003: val_loss improved from 0.24191 to 0.20766, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000003-0.207662-0.078542.hdf5\n",
      "882/882 [==============================] - 669s 759ms/step - loss: 0.0785 - acc: 0.9859 - precision: 0.9956 - recall: 0.9740 - auc: 0.9996 - val_loss: 0.2077 - val_acc: 0.9525 - val_precision: 0.9782 - val_recall: 0.9317 - val_auc: 0.9968\n",
      "lr= 0.000161\n",
      "Epoch 4/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0154 - acc: 0.9986 - precision: 0.9992 - recall: 0.9972 - auc: 1.0000\n",
      "Epoch 00004: val_loss improved from 0.20766 to 0.16167, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000004-0.161668-0.015422.hdf5\n",
      "882/882 [==============================] - 669s 759ms/step - loss: 0.0154 - acc: 0.9986 - precision: 0.9992 - recall: 0.9972 - auc: 1.0000 - val_loss: 0.1617 - val_acc: 0.9623 - val_precision: 0.9793 - val_recall: 0.9520 - val_auc: 0.9966\n",
      "lr= 0.0001298\n",
      "Epoch 5/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9995 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000\n",
      "Epoch 00005: val_loss improved from 0.16167 to 0.15038, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000005-0.150379-0.005759.hdf5\n",
      "882/882 [==============================] - 668s 757ms/step - loss: 0.0058 - acc: 0.9995 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9658 - val_precision: 0.9825 - val_recall: 0.9570 - val_auc: 0.9968\n",
      "lr= 0.00010484\n",
      "Epoch 6/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9997 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00006: val_loss improved from 0.15038 to 0.14841, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000006-0.148413-0.003516.hdf5\n",
      "882/882 [==============================] - 668s 757ms/step - loss: 0.0035 - acc: 0.9997 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.1484 - val_acc: 0.9666 - val_precision: 0.9819 - val_recall: 0.9578 - val_auc: 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr= 8.4872e-05\n",
      "Epoch 7/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00007: val_loss improved from 0.14841 to 0.14603, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000007-0.146033-0.002478.hdf5\n",
      "882/882 [==============================] - 669s 759ms/step - loss: 0.0025 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.1460 - val_acc: 0.9678 - val_precision: 0.9821 - val_recall: 0.9592 - val_auc: 0.9965\n",
      "lr= 6.88976e-05\n",
      "Epoch 8/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 0.0021 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.14603 to 0.14539, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000008-0.145388-0.002148.hdf5\n",
      "882/882 [==============================] - 669s 759ms/step - loss: 0.0021 - acc: 0.9998 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9682 - val_precision: 0.9818 - val_recall: 0.9606 - val_auc: 0.9964\n",
      "lr= 5.611808000000001e-05\n",
      "Epoch 9/9\n",
      "882/882 [==============================] - ETA: 0s - loss: 9.4804e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00009: val_loss improved from 0.14539 to 0.14027, saving model to data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000009-0.140266-0.000948.hdf5\n",
      "882/882 [==============================] - 674s 764ms/step - loss: 9.4804e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9695 - val_precision: 0.9833 - val_recall: 0.9627 - val_auc: 0.9964\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "FILENAMES = np.array(FILENAMES)\n",
    "\n",
    "#oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [] \n",
    "\n",
    "preds = np.zeros((len(TEST_FILENAMES),config['num_class']))\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True,random_state=SEED)\n",
    "for fold, (tr_index, val_index) in enumerate(skf.split(FILENAMES)):\n",
    "\n",
    "    print('#'*25); print('#### FOLD',fold+1)\n",
    "    #gc.collect()\n",
    "    \n",
    "    #print('################', 'lr=', LEARNING_RATE)\n",
    "    print(model_name)\n",
    "\n",
    "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
    "    #NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "  \n",
    "    np.random.shuffle(TRAINING_FILENAMES); print('#'*25)\n",
    "    #seed_everything(SEED)\n",
    "    \n",
    "    train_dataset = get_training_dataset(TRAINING_FILENAMES,ordered = False)\n",
    "    val_dataset = get_validation_dataset(VALIDATION_FILENAMES,ordered = True, prediction = False)\n",
    "    \n",
    "#     print('FILENAMES=', len(FILENAMES))\n",
    "#     print('TRAINING_FILENAMES=', len(TRAINING_FILENAMES))\n",
    "#     print('VALIDATION_FILENAMES=', len(VALIDATION_FILENAMES))\n",
    "    STEPS_PER_EPOCH = np.ceil(len(TRAINING_FILENAMES)/config['batch_size'])\n",
    "#     print('STEPS_PER_EPOCH=', STEPS_PER_EPOCH)\n",
    "\n",
    "    \n",
    "    model = build_cnn(config)\n",
    "\n",
    "    initial_epoch = 0\n",
    "\n",
    "#     if pth.isdir(model_path) and len([_ for _ in os.listdir(model_path) if _.endswith('hdf5')]) >= 1:\n",
    "#         for layer in model.layers[:166]:\n",
    "#             layer.trainable = False\n",
    "#         for layer in model.layers[166:]:\n",
    "#             layer.trainable = True\n",
    "            \n",
    "#         model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "#                   metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "#         model_chk_name = sorted(os.listdir(model_path))[-1]\n",
    "#         initial_epoch = int(model_chk_name.split('-')[0])\n",
    "#         model.load_weights(pth.join(model_path, model_chk_name))\n",
    "#     else:\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                 metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "    model.fit(\n",
    "        x=train_dataset, epochs=PRE_TRAIN_EPOCH, # train only top layers for just a few epochs.\n",
    "        validation_data=val_dataset, shuffle=True,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        #callbacks = [checkpointer, es], #batch_size=config['batch_size']\n",
    "        initial_epoch=initial_epoch,\n",
    "        # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "        verbose=1)\n",
    "\n",
    "#     for i, layer in enumerate(model.layers):\n",
    "#         print(i, layer.name)\n",
    "\n",
    "    for layer in model.layers[:166]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[166:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(loss=config['loss'], optimizer=Adam(lr=config['learning_rate']),\n",
    "              metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "\n",
    "    initial_epoch=PRE_TRAIN_EPOCH\n",
    "\n",
    "    # ### Freeze first layer\n",
    "    # conv_list = [layer for layer in model.layers if isinstance(layer, keras.layers.Conv2D)]\n",
    "    # conv_list[0].trainable = False\n",
    "    # # conv_list[1].trainable = False\n",
    "\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = pth.join(model_path, f'fold{fold+1:02d}-' +'{epoch:06d}-{val_loss:0.6f}-{loss:0.6f}.hdf5')\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=model_filename, verbose=1, \n",
    "        period=1, save_best_only=True, \n",
    "        monitor='val_loss'\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "\n",
    "    hist = model.fit(\n",
    "        x=train_dataset, #epochs=config['num_epoch'], \n",
    "        #batch_size = BATCH_SIZES[fold],\n",
    "        epochs=EPOCHS[fold], \n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        validation_data=val_dataset, shuffle=True,\n",
    "        callbacks = [get_lr_callback(), checkpointer], #, es], #batch_size=config['batch_size']\n",
    "        initial_epoch=0, #### JUST 0 TO FIXED EPOCH COUNT #initial_epoch,\n",
    "        # steps_per_epoch=train_num_steps, validation_steps=val_num_steps,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "#     model_chk_name = sorted(glob(pth.join(model_path, f'fold{fold+1:02d}-*')))[-1]\n",
    "#     print('selected weight to load=', model_chk_name)\n",
    "#     model.load_weights(model_chk_name)\n",
    "\n",
    "#     ct_test = len(TEST_FILENAMES)\n",
    "#     STEPS = TTA * ct_test / config['batch_size']\n",
    "#     test_dataset = get_test_dataset(TEST_FILENAMES)\n",
    "#     pred = model.predict(test_dataset,steps=STEPS, verbose=1)[:ct_test * TTA,]\n",
    "\n",
    "#     preds += np.mean(pred.reshape((ct_test, TTA, config['num_class']), order='F'), axis=1) * WGTS[fold]\n",
    "            \n",
    "    K.clear_session()\n",
    "    del(model)\n",
    "    \n",
    "#     chk_name_list = sorted([name for name in os.listdir(model_path) if name != '000000_last.hdf5'])\n",
    "#     for chk_name in chk_name_list[:-20]:\n",
    "#         os.remove(pth.join(model_path, chk_name))\n",
    "    # clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_base_path = pth.join(data_base_path, 'submission')\n",
    "os.makedirs(submission_base_path, exist_ok=True)\n",
    "today_str = datetime.date.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### FOLD 1\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold01-000008-0.157616-0.001185.hdf5\n",
      "   2/5220 [..............................] - ETA: 22:19WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0463s vs `on_predict_batch_end` time: 0.4551s). Check your callbacks.\n",
      "5221/5220 [==============================] - 2666s 511ms/step\n",
      "Saved backup pickle= data/public/submission/20201115_fold01_ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O.pkl\n",
      "######################### FOLD 2\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold02-000009-0.142421-0.000917.hdf5\n",
      "   2/5220 [..............................] - ETA: 23:18WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0725s vs `on_predict_batch_end` time: 0.4574s). Check your callbacks.\n",
      "5221/5220 [==============================] - 2670s 511ms/step\n",
      "Saved backup pickle= data/public/submission/20201115_fold02_ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O.pkl\n",
      "######################### FOLD 3\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000008-0.153127-0.001274.hdf5\n",
      "   2/5220 [..............................] - ETA: 22:55WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0594s vs `on_predict_batch_end` time: 0.4585s). Check your callbacks.\n",
      "5221/5220 [==============================] - 2669s 511ms/step\n",
      "Saved backup pickle= data/public/submission/20201115_fold03_ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O.pkl\n",
      "######################### FOLD 4\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000009-0.150363-0.000769.hdf5\n",
      "   2/5220 [..............................] - ETA: 22:37WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0595s vs `on_predict_batch_end` time: 0.4575s). Check your callbacks.\n",
      "5221/5220 [==============================] - 2669s 511ms/step\n",
      "Saved backup pickle= data/public/submission/20201115_fold04_ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O.pkl\n",
      "######################### FOLD 5\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000009-0.140266-0.000948.hdf5\n",
      "   2/5220 [..............................] - ETA: 22:21WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0502s vs `on_predict_batch_end` time: 0.4585s). Check your callbacks.\n",
      "5221/5220 [==============================] - 2669s 511ms/step\n",
      "Saved backup pickle= data/public/submission/20201115_fold05_ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O.pkl\n"
     ]
    }
   ],
   "source": [
    "TTA = 11\n",
    "import gc\n",
    "import pickle\n",
    "preds = np.zeros((len(TEST_FILENAMES),config['num_class']))\n",
    "\n",
    "ct_test = len(TEST_FILENAMES)\n",
    "STEPS = TTA * ct_test / config['batch_size']\n",
    "test_dataset = get_test_dataset(TEST_FILENAMES)\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = build_cnn(config)\n",
    "    \n",
    "    print('#' * 25, f'FOLD {fold+1}')\n",
    "    model_chk_name = sorted(glob(pth.join(model_path, f'fold{fold+1:02d}-*')))[-1]\n",
    "    print('Selected weight to load=', model_chk_name)\n",
    "    model.load_weights(model_chk_name)\n",
    "    \n",
    "    pred = model.predict(test_dataset,steps=STEPS, verbose=1)[:ct_test * TTA,]\n",
    "    \n",
    "    backup_filename = '{}.pkl'.format(model_name)\n",
    "    backup_filename = pth.join(submission_base_path, '_'.join([today_str, f'fold{fold+1:02d}', backup_filename]))\n",
    "    pickle.dump(pred, open(backup_filename, 'wb'))\n",
    "    print('Saved backup pickle=', backup_filename)\n",
    "    \n",
    "    preds += np.mean(pred.reshape((ct_test, TTA, config['num_class']), order='F'), axis=1) * WGTS[fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### FOLD 1\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold01-000008-0.157616-0.001185.hdf5\n",
      "######################### FOLD 2\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold02-000009-0.142421-0.000917.hdf5\n",
      "######################### FOLD 3\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000008-0.153127-0.001274.hdf5\n",
      "######################### FOLD 4\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000009-0.150363-0.000769.hdf5\n",
      "######################### FOLD 5\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000009-0.140266-0.000948.hdf5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pickle\n",
    "preds = np.zeros((len(TEST_FILENAMES),config['num_class']))\n",
    "\n",
    "ct_test = len(TEST_FILENAMES)\n",
    "STEPS = TTA * ct_test / config['batch_size']\n",
    "\n",
    "### Define dataset\n",
    "test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#test_dataset = test_dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#test_dataset = test_dataset.repeat()\n",
    "test_dataset = test_dataset.batch(config['batch_size'])\n",
    "test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = build_cnn(config)\n",
    "    \n",
    "    print('#' * 25, f'FOLD {fold+1}')\n",
    "    model_chk_name = sorted(glob(pth.join(model_path, f'fold{fold+1:02d}-*')))[-1]\n",
    "    print('Selected weight to load=', model_chk_name)\n",
    "    model.load_weights(model_chk_name)\n",
    "    \n",
    "    pred = model.predict(test_dataset) #,steps=STEPS, verbose=1)[:ct_test * TTA,]\n",
    "    \n",
    "#     backup_filename = '{}.pkl'.format(model_name)\n",
    "#     backup_filename = pth.join(submission_base_path, '_'.join([today_str, f'fold{fold+1:02d}', backup_filename]))\n",
    "#     pickle.dump(pred, open(backup_filename, 'wb'))\n",
    "#     print('Saved backup pickle=', backup_filename)\n",
    "\n",
    "    #preds += np.mean(pred.reshape((ct_test, config['num_class']), order='F'), axis=1) * WGTS[fold]\n",
    "    preds += pred.reshape((ct_test, config['num_class']), order='F') * WGTS[fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_filename = '{}.pkl'.format(model_name)\n",
    "backup_filename = pth.join(submission_base_path, '_'.join([today_str, 'foldsum', backup_filename]))\n",
    "preds = pickle.load(open(backup_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id  conf\n",
       "0  xlf1tgh2ih            1     1\n",
       "1  68a3ot4osk            1     1\n",
       "2  si2lek4u0a            1     1\n",
       "3  rmtqxhipnv            1     1\n",
       "4  2flmjdud0e            1     1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.86932685e-15, 1.05271557e-14, 2.19919058e-09, ...,\n",
       "        1.93643361e-07, 2.93653789e-16, 2.22923098e-15],\n",
       "       [2.84325531e-09, 1.39899499e-06, 2.39197487e-10, ...,\n",
       "        2.07086359e-07, 9.14533707e-11, 5.19558255e-08],\n",
       "       [9.35601032e-12, 1.21231353e-10, 1.77971364e-11, ...,\n",
       "        4.51543549e-10, 6.63308984e-09, 1.73118596e-06],\n",
       "       ...,\n",
       "       [7.67897839e-11, 1.62504120e-11, 4.21048289e-12, ...,\n",
       "        3.75667339e-07, 5.06268435e-09, 1.22035844e-08],\n",
       "       [3.03047310e-06, 2.20537029e-04, 8.87608438e-10, ...,\n",
       "        1.08848243e-07, 5.82922291e-06, 2.62103441e-04],\n",
       "       [5.60695013e-12, 1.43646909e-11, 1.31387127e-11, ...,\n",
       "        9.48670953e-11, 2.09982727e-12, 4.70440506e-10]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argsort(-preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = submission_df.copy()\n",
    "\n",
    "tmp_labels = pred_labels[:, 0]  # top 1\n",
    "tmp_df['id'] = [x.split('/')[3].split('.')[0] for x in TEST_FILENAMES]  # order is different. THIS IS IMPORTANT\n",
    "tmp_df['landmark_id'] = tmp_labels\n",
    "tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "del submission_df['landmark_id']\n",
    "del submission_df['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(submission_df, tmp_df, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(submission_csv_fileaname_top1, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "backup_filename = '{}.pkl'.format(model_name)\n",
    "backup_filename = pth.join(submission_base_path, '_'.join([today_str, 'foldsum', backup_filename]))\n",
    "pickle.dump(preds, open(backup_filename, 'wb'))\n",
    "print('Saved backup pickle=', backup_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inference\n",
    "\n",
    "\n",
    "pred_labels = np.argsort(-preds)\n",
    "\n",
    "submission_csv_path = pth.join(data_base_path, submission_csv_name)\n",
    "submission_df = pd.read_csv(submission_csv_path)\n",
    "\n",
    "today_str = datetime.date.today().strftime('%Y%m%d')\n",
    "result_filename = '{}.csv'.format(model_name)\n",
    "submission_csv_fileaname = pth.join(submission_base_path, '_'.join([today_str, result_filename]))\n",
    "submission_csv_fileaname_top1 = pth.join(submission_base_path, '_'.join([today_str, 'top1', result_filename]))\n",
    "\n",
    "merged_df = []\n",
    "\n",
    "RANK_TO_SAVE = 5\n",
    "for i in range(RANK_TO_SAVE):\n",
    "    tmp_df = submission_df.copy()\n",
    "\n",
    "    tmp_labels = pred_labels[:, i]\n",
    "    tmp_df['landmark_id'] = tmp_labels\n",
    "    tmp_df['conf'] = np.array([pred[indice] for pred, indice in zip(preds, tmp_labels)])\n",
    "    if i == 0:\n",
    "        tmp_df.to_csv(submission_csv_fileaname_top1, index=False)\n",
    "    merged_df.append(tmp_df)\n",
    "\n",
    "submission_df = pd.concat(merged_df)\n",
    "\n",
    "\n",
    "submission_df.to_csv(submission_csv_fileaname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### FOLD 1\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold01-000008-0.157616-0.001185.hdf5\n",
      "######################### FOLD 2\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold02-000009-0.142421-0.000917.hdf5\n",
      "######################### FOLD 3\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold03-000008-0.153127-0.001274.hdf5\n",
      "######################### FOLD 4\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold04-000009-0.150363-0.000769.hdf5\n",
      "######################### FOLD 5\n",
      "Selected weight to load= data/public/checkpoint/ResNet50V2-kfold_resize_270_conv_0_basech_0_act_relu_pool_X_betw_avg_fc_0_zscore_True_batch_80_BN_O/fold05-000009-0.140266-0.000948.hdf5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pickle\n",
    "preds = np.zeros((len(TEST_FILENAMES),config['num_class']))\n",
    "\n",
    "ct_test = len(TEST_FILENAMES)\n",
    "STEPS = TTA * ct_test / config['batch_size']\n",
    "\n",
    "### Define dataset\n",
    "test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "test_dataset = test_dataset.map(_parse_image_function_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(map_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(resize_and_crop_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#test_dataset = test_dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#test_dataset = test_dataset.repeat()\n",
    "test_dataset = test_dataset.batch(config['batch_size'])\n",
    "test_dataset = test_dataset.map(post_process_func_for_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = build_cnn(config)\n",
    "    \n",
    "    print('#' * 25, f'FOLD {fold+1}')\n",
    "    model_chk_name = sorted(glob(pth.join(model_path, f'fold{fold+1:02d}-*')))[-1]\n",
    "    print('Selected weight to load=', model_chk_name)\n",
    "    model.load_weights(model_chk_name)\n",
    "    \n",
    "    pred = model.predict(test_dataset) #,steps=STEPS, verbose=1)[:ct_test * TTA,]\n",
    "    \n",
    "#     backup_filename = '{}.pkl'.format(model_name)\n",
    "#     backup_filename = pth.join(submission_base_path, '_'.join([today_str, f'fold{fold+1:02d}', backup_filename]))\n",
    "#     pickle.dump(pred, open(backup_filename, 'wb'))\n",
    "#     print('Saved backup pickle=', backup_filename)\n",
    "\n",
    "    #preds += np.mean(pred.reshape((ct_test, config['num_class']), order='F'), axis=1) * WGTS[fold]\n",
    "    preds += pred.reshape((ct_test, config['num_class']), order='F') * WGTS[fold]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Training_MobileNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
